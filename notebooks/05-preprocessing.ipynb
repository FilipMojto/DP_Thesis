{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262d8bc5",
   "metadata": {},
   "source": [
    "# 05 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9bacf",
   "metadata": {},
   "source": [
    "## 5.1 - Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63351fa",
   "metadata": {},
   "source": [
    "### 5.1.1 - Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ebf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_config import setup_notebook_logging\n",
    "\n",
    "logger, log_start, log_check, log_result = setup_notebook_logging(label=\"PREPROCESSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39586ea7",
   "metadata": {},
   "source": [
    "### 5.1.2 Configuring Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7596c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Setting up root by appending the parent to the sys...\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Setting up root by appending the parent to the sys...\", print_to_console=True)\n",
    "from jupyter_init import setup\n",
    "\n",
    "setup()\n",
    "\n",
    "from src_code.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106823f",
   "metadata": {},
   "source": [
    "### 5.1.3 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a551fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Loading the dataset...\n",
      "C:\\Users\\fmojt\\Code\\DPThesis\\DP_Thesis\\data\\interim\\test_labeled_features_partial_v10.feather\n",
      "[PREPROCESSING RESULT] Loaded dataframe with 7363 rows and 31 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Loading the dataset...\", print_to_console=True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# TARGET_DF_FILE = ETL_MAPPINGS['test']['current_newest']\n",
    "subset: SubsetType = 'test'\n",
    "TARGET_DF_FILE = PREPROCESSING_MAPPINGS[subset]['input']\n",
    "print(ETL_MAPPINGS[subset]['current_newest'])\n",
    "\n",
    "# ---- LOAD ----\n",
    "df = pd.read_feather(TARGET_DF_FILE)\n",
    "log_result(f\"Loaded dataframe with {len(df)} rows and {len(df.columns)} columns\\n\", print_to_console=True)\n",
    "\n",
    "# For large datasets\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963d811",
   "metadata": {},
   "source": [
    "## 5.2 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c15062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[])\n",
    "# append a transformer tuple (name, transformer, columns)\n",
    "# preprocessor.transformers.append(('new_passthrough', 'passthrough', ['col1', 'col2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b4a61",
   "metadata": {},
   "source": [
    "### 5.2.1 Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477e8eb",
   "metadata": {},
   "source": [
    "#### 5.2.1.1 - Fix negative values before log transform\n",
    "Some features (e.g., time_since_last_change) contain negative values.\n",
    "\n",
    "We shift them to be ≥ 0 before applying log1p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73d379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 0 rows with negative time_since_last_change\n"
     ]
    }
   ],
   "source": [
    "# def shift_min_to_zero(df, col):\n",
    "#     \"\"\"Shift column so minimum is 0 if negative values exist.\"\"\"\n",
    "#     min_val = df[col].min()\n",
    "#     if min_val < 0:\n",
    "#         df[col] = df[col] - min_val\n",
    "#     return df\n",
    "\n",
    "# for col in NUMERIC_FEATURES:\n",
    "#     df = shift_min_to_zero(df, col)\n",
    "\n",
    "from notebooks.utils import contains_negative\n",
    "from notebooks.constants import NUMERIC_FEATURES\n",
    "\n",
    "NEG_FEATURES_TO_DROP = ['time_since_last_change']\n",
    "\n",
    "# List of features to check: NUMERIC_FEATURES excluding NEG_FEATURES_TO_DROP\n",
    "features_to_check = [\n",
    "    col for col in NUMERIC_FEATURES \n",
    "    if col not in NEG_FEATURES_TO_DROP\n",
    "]\n",
    "\n",
    "# Check if any of the features in features_to_check contain negative values\n",
    "if any(contains_negative(df, col) for col in features_to_check):\n",
    "    # If True, raise an exception\n",
    "    raise ValueError(\"Unexpected negative values found in one or more numeric features that are NOT set to be dropped.\")\n",
    "\n",
    "\n",
    "neg_mask = df[\"time_since_last_change\"] < 0\n",
    "n_neg = neg_mask.sum()\n",
    "\n",
    "print(f\"Dropping {n_neg} rows with negative time_since_last_change\")\n",
    "\n",
    "df = df[~neg_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ac218",
   "metadata": {},
   "source": [
    "#### 5.2.1.2 Assertion Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b75e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] [NEG_FEATURES_TO_DROP] Performing assertion check...\n",
      "[PREPROCESSING RESULT] [NEG_FEATURES_TO_DROP] Check succesfull!\n"
     ]
    }
   ],
   "source": [
    "log_check(\"[NEG_FEATURES_TO_DROP] Performing assertion check...\")\n",
    "assert(any(contains_negative(df, col) for col in NEG_FEATURES_TO_DROP) == False)\n",
    "log_result(\"[NEG_FEATURES_TO_DROP] Check succesfull!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563eeb35",
   "metadata": {},
   "source": [
    "### 5.2.2 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8f4ea",
   "metadata": {},
   "source": [
    "#### 5.2.2.1 - Winsorization (IQR-base)\n",
    "\n",
    "Applies the same bounds your EDA used.\n",
    "\n",
    "You want preprocessing to match your EDA findings, so we clamp values to the lower/upper fences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b487378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Detected test subset. Loading fitted preprocessor...\n",
      "[PREPROCESSING RESULT] Transformations applied successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from notebooks.transformers import WinsorizerIQR\n",
    "from notebooks.constants import NUMERIC_FEATURES, LINE_TOKEN_FEATURES\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output='pandas')\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=False)\n",
    "\n",
    "if subset == 'train':\n",
    "    log_check(\"Detected train subset. Creating new preprocessor...\", print_to_console=True)\n",
    "    preprocessor = ColumnTransformer(transformers=[])\n",
    "\n",
    "    preprocessor.transformers.append(('winsorize', WinsorizerIQR(factor=1.5), NUMERIC_FEATURES))\n",
    "    preprocessor.transformers.append(('log_tokens', log_transformer, LINE_TOKEN_FEATURES))\n",
    "    preprocessor.transformers.append(('log_numeric', log_transformer, NUMERIC_FEATURES))\n",
    "\n",
    "    # 3. FIT the preprocessor ONLY on the training data\n",
    "    preprocessor.fit(df)\n",
    "    df = preprocessor.transform(df)\n",
    "\n",
    "    # 4. SAVE the fitted preprocessor\n",
    "    # The saved object contains all the calculated Q1, Q3 bounds.\n",
    "    joblib.dump(preprocessor, FITTED_PREPROCESSOR)\n",
    "\n",
    "    # print(\"Fitted preprocessor saved to fitted_preprocessor.joblib\")\n",
    "elif subset in ('test', 'validate'):\n",
    "    log_check(\"Detected test subset. Loading fitted preprocessor...\", print_to_console=True)\n",
    "    loaded_preprocessor = joblib.load(FITTED_PREPROCESSOR)\n",
    "    df = loaded_preprocessor.transform(df)\n",
    "else:\n",
    "    msg = \"Unknown subset value!\"\n",
    "    logger.error(msg)\n",
    "    raise ValueError(msg)\n",
    "\n",
    "\n",
    "log_result(\"Transformations applied successfully.\", print_to_console=True)\n",
    "\n",
    "\n",
    "# def winsorize_iqr(df, col, preserve_original: bool = False):\n",
    "#     \"\"\"\n",
    "#     Caps extreme outliers using IQR fences.\n",
    "#     Keeps the distribution shape mostly intact.\n",
    "#     \"\"\"\n",
    "#     Q1 = df[col].quantile(0.25)\n",
    "#     Q3 = df[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower = Q1 - 1.5 * IQR\n",
    "#     upper = Q3 + 1.5 * IQR\n",
    "\n",
    "#     print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "#     new_col_name = col + \"_winsorized\" if preserve_original else col\n",
    "\n",
    "#     df[new_col_name] = df[col].clip(lower=lower, upper=upper)\n",
    "#     print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# --- Apply to all numeric columns ---\n",
    "# for col in NUMERIC_FEATURES:\n",
    "#     df = winsorize_iqr(df, col, preserve_original=True) if col == 'recent_churn' else winsorize_iqr(df, col)\n",
    "\n",
    "# for col in LINE_TOKEN_FEATURES:\n",
    "#     # df = winsorize_iqr(df, col)\n",
    "#     df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4cf37",
   "metadata": {},
   "source": [
    "<!-- ### 5.2.2 - Fix negative values before log transform\n",
    "Some features (e.g., time_since_last_change) contain negative values.\n",
    "\n",
    "We shift them to be ≥ 0 before applying log1p: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0151761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def shift_min_to_zero(df, col):\n",
    "# #     \"\"\"Shift column so minimum is 0 if negative values exist.\"\"\"\n",
    "# #     min_val = df[col].min()\n",
    "# #     if min_val < 0:\n",
    "# #         df[col] = df[col] - min_val\n",
    "# #     return df\n",
    "\n",
    "# # for col in NUMERIC_FEATURES:\n",
    "# #     df = shift_min_to_zero(df, col)\n",
    "\n",
    "# from notebooks.utils import contains_negative\n",
    "# from notebooks.constants import NUMERIC_FEATURES\n",
    "\n",
    "# NEG_FEATURES_TO_DROP = ['time_since_last_change']\n",
    "\n",
    "# # List of features to check: NUMERIC_FEATURES excluding NEG_FEATURES_TO_DROP\n",
    "# features_to_check = [\n",
    "#     col for col in NUMERIC_FEATURES \n",
    "#     if col not in NEG_FEATURES_TO_DROP\n",
    "# ]\n",
    "\n",
    "# # Check if any of the features in features_to_check contain negative values\n",
    "# if any(contains_negative(df, col) for col in features_to_check):\n",
    "#     # If True, raise an exception\n",
    "#     raise ValueError(\"Unexpected negative values found in one or more numeric features that are NOT set to be dropped.\")\n",
    "\n",
    "\n",
    "# neg_mask = df[\"time_since_last_change\"] < 0\n",
    "# n_neg = neg_mask.sum()\n",
    "\n",
    "# print(f\"Dropping {n_neg} rows with negative time_since_last_change\")\n",
    "\n",
    "# df = df[~neg_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec505e",
   "metadata": {},
   "source": [
    "### 5.2.3 - Log1p Transformation\n",
    "Reduces heavy right-skew (your EDA showed skews up to 100+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6892df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in NUMERIC_FEATURES:\n",
    "#     df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a70b5",
   "metadata": {},
   "source": [
    "## 5.3. - Save preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbcbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Saving the preprocessed dataset...\n",
      "[PREPROCESSING RESULT] Preprocessed dataset saved to C:\\Users\\fmojt\\Code\\DPThesis\\DP_Thesis\\data\\processed\\test_preprocessed.feather\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Saving the preprocessed dataset...\", print_to_console=True)\n",
    "\n",
    "OUTPUT_PATH = PREPROCESSING_MAPPINGS[subset]['output']\n",
    "\n",
    "# 1. Get the names of the final features\n",
    "# feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# 2. Reconstruct the DataFrame\n",
    "# df_transformed = pd.DataFrame(df, columns=feature_names)\n",
    "\n",
    "df.to_feather(OUTPUT_PATH)\n",
    "\n",
    "log_result(f\"Preprocessed dataset saved to {OUTPUT_PATH}\", print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30464f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['winsorize__author_exp_pre', 'winsorize__author_recent_activity_pre',\n",
       "       'winsorize__loc_added', 'winsorize__loc_deleted',\n",
       "       'winsorize__files_changed', 'winsorize__hunks_count',\n",
       "       'winsorize__msg_len', 'winsorize__ast_delta',\n",
       "       'winsorize__complexity_delta', 'winsorize__max_func_change',\n",
       "       'winsorize__time_since_last_change', 'winsorize__recent_churn',\n",
       "       'log_tokens__todo', 'log_tokens__fixme', 'log_tokens__try',\n",
       "       'log_tokens__except', 'log_tokens__raise',\n",
       "       'log_numeric__author_exp_pre',\n",
       "       'log_numeric__author_recent_activity_pre', 'log_numeric__loc_added',\n",
       "       'log_numeric__loc_deleted', 'log_numeric__files_changed',\n",
       "       'log_numeric__hunks_count', 'log_numeric__msg_len',\n",
       "       'log_numeric__ast_delta', 'log_numeric__complexity_delta',\n",
       "       'log_numeric__max_func_change', 'log_numeric__time_since_last_change',\n",
       "       'log_numeric__recent_churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP_Thesis-sh7Ft33M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
