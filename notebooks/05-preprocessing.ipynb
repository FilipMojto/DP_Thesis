{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262d8bc5",
   "metadata": {},
   "source": [
    "# 05 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9bacf",
   "metadata": {},
   "source": [
    "## 5.1 - Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63351fa",
   "metadata": {},
   "source": [
    "### 5.1.1 - Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4ebf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_config import NotebookLogger\n",
    "from constants import LOG_FILE\n",
    "logger = NotebookLogger(label=\"PREPROCESSING\", notebook_name=None, file_log_path=LOG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39586ea7",
   "metadata": {},
   "source": [
    "### 5.1.2 Project Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7596c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Setting up root by appending the parent to the sys...\n",
      "[PREPROCESSING RESULT] Done.\n"
     ]
    }
   ],
   "source": [
    "from jupyter_init import setup\n",
    "from config import setup as cfg_setup\n",
    "\n",
    "logger.log_check(\"Setting up root by appending the parent to the sys...\", print_to_console=True)\n",
    "\n",
    "setup()\n",
    "cfg_setup()\n",
    "\n",
    "logger.log_result(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12db75e",
   "metadata": {},
   "source": [
    "### 5.1.3 Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1286f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# System & External Libs\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# My Libs\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from src_code.config import FITTED_TRANSFORMER\n",
    "from src_code.ml_pipeline.preprocessing.transform import transform\n",
    "from src_code.config import *\n",
    "from src_code.ml_pipeline.df_load import load_df\n",
    "from src_code.ml_pipeline.preprocessing.transform import pca_explained_variance\n",
    "from src_code.ml_pipeline.df_load import save_df\n",
    "from src_code.ml_pipeline.preprocessing.preprocessing import drop_invalid_rows\n",
    "from juputils import display_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106823f",
   "metadata": {},
   "source": [
    "### 5.1.4 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a551fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Loading the dataset...\n",
      "C:\\Users\\fmojt\\Code\\DPThesis\\DP_Thesis\\data\\interim\\test_labeled_features_partial_v10.feather\n",
      "[PREPROCESSING CHECK] Loading the dataset...\n",
      "[PREPROCESSING RESULT] Loaded dataframe with 7363 rows and 31 columns\n",
      "\n",
      "[PREPROCESSING RESULT] Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "logger.log_check(\"Loading the dataset...\", print_to_console=True)\n",
    "\n",
    "# TARGET_DF_FILE = ETL_MAPPINGS['test']['current_newest']\n",
    "subset: SubsetType = 'test'\n",
    "TARGET_DF_FILE = PREPROCESSING_MAPPINGS[subset]['input']\n",
    "print(ETL_MAPPINGS[subset]['current_newest'])\n",
    "\n",
    "# ---- LOAD ----\n",
    "df = load_df(df_file_path=TARGET_DF_FILE, logger=logger)\n",
    "# df = pd.read_feather(TARGET_DF_FILE)\n",
    "# log_result(f\"Loaded dataframe with {len(df)} rows and {len(df.columns)} columns\\n\", print_to_console=True)\n",
    "\n",
    "# # For large datasets\n",
    "# pd.set_option('display.max_columns', 50)\n",
    "# sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"muted\")\n",
    "logger.log_result(\"Dataset loaded successfully.\", print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963d811",
   "metadata": {},
   "source": [
    "## 5.2 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c15062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer(transformers=[])\n",
    "# append a transformer tuple (name, transformer, columns)\n",
    "# preprocessor.transformers.append(('new_passthrough', 'passthrough', ['col1', 'col2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b4a61",
   "metadata": {},
   "source": [
    "### 5.2.1 Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477e8eb",
   "metadata": {},
   "source": [
    "#### 5.2.1.1 - Fix negative values before log transform\n",
    "Some features (e.g., time_since_last_change) contain negative values.\n",
    "\n",
    "We shift them to be â‰¥ 0 before applying log1p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c40656ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-CodeCell .highlight,\n",
       ".output pre,\n",
       ".output code {\n",
       "    background-color: #111111 !important;\n",
       "    color: #94d4d4 !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">drop_invalid_rows</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">DataFrame</span><span class=\"p\">,</span>\n",
       "    <span class=\"c1\"># numeric_features: Iterable[str],</span>\n",
       "    <span class=\"n\">row_filters</span><span class=\"p\">:</span> <span class=\"n\">Dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">Callable</span><span class=\"p\">[[</span><span class=\"n\">Series</span><span class=\"p\">],</span> <span class=\"n\">Series</span><span class=\"p\">]],</span>\n",
       "    <span class=\"n\">logger</span><span class=\"p\">:</span> <span class=\"n\">NotebookLogger</span> <span class=\"o\">=</span> <span class=\"n\">DEF_NOTEBOOK_LOGGER</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">print_to_console</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">sanity_check</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">DataFrame</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_check</span><span class=\"p\">(</span>\n",
       "        <span class=\"s2\">&quot;Applying row-level filters on numeric features...&quot;</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">print_to_console</span><span class=\"o\">=</span><span class=\"n\">print_to_console</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Validate filter columns</span>\n",
       "    <span class=\"k\">for</span> <span class=\"n\">col</span> <span class=\"ow\">in</span> <span class=\"n\">row_filters</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">col</span> <span class=\"ow\">not</span> <span class=\"ow\">in</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">columns</span><span class=\"o\">.</span><span class=\"n\">to_list</span><span class=\"p\">():</span>\n",
       "            <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Filter column &#39;</span><span class=\"si\">{</span><span class=\"n\">col</span><span class=\"si\">}</span><span class=\"s2\">&#39; is not a numeric feature.&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Build combined mask (AND across all filters)</span>\n",
       "    <span class=\"n\">valid_mask</span> <span class=\"o\">=</span> <span class=\"n\">Series</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">index</span><span class=\"o\">=</span><span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">for</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"n\">predicate</span> <span class=\"ow\">in</span> <span class=\"n\">row_filters</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>\n",
       "        <span class=\"n\">col_mask</span> <span class=\"o\">=</span> <span class=\"n\">predicate</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">])</span>\n",
       "        <span class=\"n\">valid_mask</span> <span class=\"o\">&amp;=</span> <span class=\"n\">col_mask</span>\n",
       "\n",
       "        <span class=\"c1\"># how many rows failed this filter, inversion is needed</span>\n",
       "        <span class=\"n\">n_dropped</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"o\">~</span><span class=\"n\">col_mask</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">()</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_result</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Dropping </span><span class=\"si\">{</span><span class=\"n\">n_dropped</span><span class=\"si\">}</span><span class=\"s2\"> rows due to filter on &#39;</span><span class=\"si\">{</span><span class=\"n\">col</span><span class=\"si\">}</span><span class=\"s2\">&#39;&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># keeps only rows where the mask is true,the rest is dropped</span>\n",
       "    <span class=\"c1\"># the reset index removes gaps caused by dropped rows</span>\n",
       "    <span class=\"c1\"># By default, pandas tries to save your old index as a new column.</span>\n",
       "    <span class=\"c1\"># drop=True tells pandas to drop the old index instead of keeping it.</span>\n",
       "    <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">valid_mask</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">reset_index</span><span class=\"p\">(</span><span class=\"n\">drop</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">if</span> <span class=\"n\">sanity_check</span><span class=\"p\">:</span>\n",
       "        <span class=\"c1\"># Final sanity check (defensive programming)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">col</span><span class=\"p\">,</span> <span class=\"n\">predicate</span> <span class=\"ow\">in</span> <span class=\"n\">row_filters</span><span class=\"o\">.</span><span class=\"n\">items</span><span class=\"p\">():</span>\n",
       "            <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">predicate</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">[</span><span class=\"n\">col</span><span class=\"p\">])</span><span class=\"o\">.</span><span class=\"n\">all</span><span class=\"p\">():</span>\n",
       "                <span class=\"k\">raise</span> <span class=\"ne\">AssertionError</span><span class=\"p\">(</span>\n",
       "                    <span class=\"sa\">f</span><span class=\"s2\">&quot;Filtering failed: column &#39;</span><span class=\"si\">{</span><span class=\"n\">col</span><span class=\"si\">}</span><span class=\"s2\">&#39; still contains invalid rows.&quot;</span>\n",
       "                <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">df</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{drop\\PYZus{}invalid\\PYZus{}rows}\\PY{p}{(}\n",
       "    \\PY{n}{df}\\PY{p}{:} \\PY{n}{DataFrame}\\PY{p}{,}\n",
       "    \\PY{c+c1}{\\PYZsh{} numeric\\PYZus{}features: Iterable[str],}\n",
       "    \\PY{n}{row\\PYZus{}filters}\\PY{p}{:} \\PY{n}{Dict}\\PY{p}{[}\\PY{n+nb}{str}\\PY{p}{,} \\PY{n}{Callable}\\PY{p}{[}\\PY{p}{[}\\PY{n}{Series}\\PY{p}{]}\\PY{p}{,} \\PY{n}{Series}\\PY{p}{]}\\PY{p}{]}\\PY{p}{,}\n",
       "    \\PY{n}{logger}\\PY{p}{:} \\PY{n}{NotebookLogger} \\PY{o}{=} \\PY{n}{DEF\\PYZus{}NOTEBOOK\\PYZus{}LOGGER}\\PY{p}{,}\n",
       "    \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{p}{:} \\PY{n+nb}{bool} \\PY{o}{=} \\PY{k+kc}{True}\\PY{p}{,}\n",
       "    \\PY{n}{sanity\\PYZus{}check}\\PY{p}{:} \\PY{n+nb}{bool} \\PY{o}{=} \\PY{k+kc}{False}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{DataFrame}\\PY{p}{:}\n",
       "    \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}check}\\PY{p}{(}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Applying row\\PYZhy{}level filters on numeric features...}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "        \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{o}{=}\\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{p}{,}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Validate filter columns}\n",
       "    \\PY{k}{for} \\PY{n}{col} \\PY{o+ow}{in} \\PY{n}{row\\PYZus{}filters}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n}{col} \\PY{o+ow}{not} \\PY{o+ow}{in} \\PY{n}{df}\\PY{o}{.}\\PY{n}{columns}\\PY{o}{.}\\PY{n}{to\\PYZus{}list}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{raise} \\PY{n+ne}{ValueError}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Filter column }\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{col}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{ is not a numeric feature.}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Build combined mask (AND across all filters)}\n",
       "    \\PY{n}{valid\\PYZus{}mask} \\PY{o}{=} \\PY{n}{Series}\\PY{p}{(}\\PY{k+kc}{True}\\PY{p}{,} \\PY{n}{index}\\PY{o}{=}\\PY{n}{df}\\PY{o}{.}\\PY{n}{index}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{for} \\PY{n}{col}\\PY{p}{,} \\PY{n}{predicate} \\PY{o+ow}{in} \\PY{n}{row\\PYZus{}filters}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{col\\PYZus{}mask} \\PY{o}{=} \\PY{n}{predicate}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{n}{col}\\PY{p}{]}\\PY{p}{)}\n",
       "        \\PY{n}{valid\\PYZus{}mask} \\PY{o}{\\PYZam{}}\\PY{o}{=} \\PY{n}{col\\PYZus{}mask}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} how many rows failed this filter, inversion is needed}\n",
       "        \\PY{n}{n\\PYZus{}dropped} \\PY{o}{=} \\PY{p}{(}\\PY{o}{\\PYZti{}}\\PY{n}{col\\PYZus{}mask}\\PY{p}{)}\\PY{o}{.}\\PY{n}{sum}\\PY{p}{(}\\PY{p}{)}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}result}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Dropping }\\PY{l+s+si}{\\PYZob{}}\\PY{n}{n\\PYZus{}dropped}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{ rows due to filter on }\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{col}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} keeps only rows where the mask is true,the rest is dropped}\n",
       "    \\PY{c+c1}{\\PYZsh{} the reset index removes gaps caused by dropped rows}\n",
       "    \\PY{c+c1}{\\PYZsh{} By default, pandas tries to save your old index as a new column.}\n",
       "    \\PY{c+c1}{\\PYZsh{} drop=True tells pandas to drop the old index instead of keeping it.}\n",
       "    \\PY{n}{df} \\PY{o}{=} \\PY{n}{df}\\PY{p}{[}\\PY{n}{valid\\PYZus{}mask}\\PY{p}{]}\\PY{o}{.}\\PY{n}{reset\\PYZus{}index}\\PY{p}{(}\\PY{n}{drop}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{if} \\PY{n}{sanity\\PYZus{}check}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} Final sanity check (defensive programming)}\n",
       "        \\PY{k}{for} \\PY{n}{col}\\PY{p}{,} \\PY{n}{predicate} \\PY{o+ow}{in} \\PY{n}{row\\PYZus{}filters}\\PY{o}{.}\\PY{n}{items}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{if} \\PY{o+ow}{not} \\PY{n}{predicate}\\PY{p}{(}\\PY{n}{df}\\PY{p}{[}\\PY{n}{col}\\PY{p}{]}\\PY{p}{)}\\PY{o}{.}\\PY{n}{all}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{k}{raise} \\PY{n+ne}{AssertionError}\\PY{p}{(}\n",
       "                    \\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Filtering failed: column }\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{col}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{ still contains invalid rows.}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "                \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{df}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "def drop_invalid_rows(\n",
       "    df: DataFrame,\n",
       "    # numeric_features: Iterable[str],\n",
       "    row_filters: Dict[str, Callable[[Series], Series]],\n",
       "    logger: NotebookLogger = DEF_NOTEBOOK_LOGGER,\n",
       "    print_to_console: bool = True,\n",
       "    sanity_check: bool = False,\n",
       ") -> DataFrame:\n",
       "    logger.log_check(\n",
       "        \"Applying row-level filters on numeric features...\",\n",
       "        print_to_console=print_to_console,\n",
       "    )\n",
       "\n",
       "    # Validate filter columns\n",
       "    for col in row_filters:\n",
       "        if col not in df.columns.to_list():\n",
       "            raise ValueError(f\"Filter column '{col}' is not a numeric feature.\")\n",
       "\n",
       "    # Build combined mask (AND across all filters)\n",
       "    valid_mask = Series(True, index=df.index)\n",
       "\n",
       "    for col, predicate in row_filters.items():\n",
       "        col_mask = predicate(df[col])\n",
       "        valid_mask &= col_mask\n",
       "\n",
       "        # how many rows failed this filter, inversion is needed\n",
       "        n_dropped = (~col_mask).sum()\n",
       "        logger.log_result(f\"Dropping {n_dropped} rows due to filter on '{col}'\")\n",
       "\n",
       "    # keeps only rows where the mask is true,the rest is dropped\n",
       "    # the reset index removes gaps caused by dropped rows\n",
       "    # By default, pandas tries to save your old index as a new column.\n",
       "    # drop=True tells pandas to drop the old index instead of keeping it.\n",
       "    df = df[valid_mask].reset_index(drop=True)\n",
       "\n",
       "    if sanity_check:\n",
       "        # Final sanity check (defensive programming)\n",
       "        for col, predicate in row_filters.items():\n",
       "            if not predicate(df[col]).all():\n",
       "                raise AssertionError(\n",
       "                    f\"Filtering failed: column '{col}' still contains invalid rows.\"\n",
       "                )\n",
       "\n",
       "    return df"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_func(drop_invalid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d73d379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Applying row-level filters on numeric features...\n",
      "[PREPROCESSING RESULT] Dropping 0 rows due to filter on 'time_since_last_change'\n"
     ]
    }
   ],
   "source": [
    "# def shift_min_to_zero(df, col):\n",
    "#     \"\"\"Shift column so minimum is 0 if negative values exist.\"\"\"\n",
    "#     min_val = df[col].min()\n",
    "#     if min_val < 0:\n",
    "#         df[col] = df[col] - min_val\n",
    "#     return df\n",
    "\n",
    "# for col in NUMERIC_FEATURES:\n",
    "#     df = shift_min_to_zero(df, col)\n",
    "\n",
    "# NEG_FEATURES_TO_DROP = [\"time_since_last_change\"]\n",
    "\n",
    "# # List of features to check: NUMERIC_FEATURES excluding NEG_FEATURES_TO_DROP\n",
    "# features_to_check = [col for col in NUMERIC_FEATURES if col not in NEG_FEATURES_TO_DROP]\n",
    "\n",
    "df = drop_invalid_rows(\n",
    "    df=df,\n",
    "    # numeric_features=NUMERIC_FEATURES,\n",
    "    row_filters={\"time_since_last_change\": lambda s: s >= 0},\n",
    "    logger=logger,\n",
    "    sanity_check=True\n",
    ")\n",
    "\n",
    "# # Check if any of the features in features_to_check contain negative values\n",
    "# if any(contains_negative(df, col) for col in features_to_check):\n",
    "#     # If True, raise an exception\n",
    "#     raise ValueError(\"Unexpected negative values found in one or more numeric features that are NOT set to be dropped.\")\n",
    "\n",
    "\n",
    "# neg_mask = df[\"time_since_last_change\"] < 0\n",
    "# n_neg = neg_mask.sum()\n",
    "\n",
    "# print(f\"Dropping {n_neg} rows with negative time_since_last_change\")\n",
    "\n",
    "# df = df[~neg_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ac218",
   "metadata": {},
   "source": [
    "#### 5.2.1.2 Assertion Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38b75e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_check(\"[NEG_FEATURES_TO_DROP] Performing assertion check...\")\n",
    "# assert(any(contains_negative(df, col) for col in NEG_FEATURES_TO_DROP) == False)\n",
    "# log_result(\"[NEG_FEATURES_TO_DROP] Check succesfull!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563eeb35",
   "metadata": {},
   "source": [
    "### 5.2.2 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ae082",
   "metadata": {},
   "source": [
    "#### 5.2.2.1 - Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85379de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8f4ea",
   "metadata": {},
   "source": [
    "#### 5.2.2.2 - Transformations\n",
    "\n",
    "Applies the same bounds your EDA used.\n",
    "\n",
    "You want preprocessing to match your EDA findings, so we clamp values to the lower/upper fences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c73e8a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-CodeCell .highlight,\n",
       ".output pre,\n",
       ".output code {\n",
       "    background-color: #111111 !important;\n",
       "    color: #94d4d4 !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">transform</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">subset</span><span class=\"p\">:</span> <span class=\"n\">SubsetType</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">random_state</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">logger</span><span class=\"p\">:</span> <span class=\"n\">NotebookLogger</span> <span class=\"o\">=</span> <span class=\"n\">DEF_NOTEBOOK_LOGGER</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">fitted_transformer</span><span class=\"p\">:</span> <span class=\"n\">Path</span> <span class=\"o\">=</span> <span class=\"n\">FITTED_TRANSFORMER</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">print_to_console</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">):</span>\n",
       "    <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_check</span><span class=\"p\">(</span><span class=\"s2\">&quot;Performing df transformation...&quot;</span><span class=\"p\">)</span>\n",
       "    <span class=\"c1\"># set_config(transform_output=&quot;pandas&quot;)</span>\n",
       "    <span class=\"c1\"># log_transformer = FunctionTransformer(np.log1p, validate=False)</span>\n",
       "\n",
       "    <span class=\"k\">if</span> <span class=\"n\">subset</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;train&quot;</span><span class=\"p\">:</span>\n",
       "        <span class=\"c1\"># log_check(&quot;Detected train subset. Creating new preprocessor...&quot;, print_to_console=True)</span>\n",
       "        <span class=\"c1\"># preprocessor = ColumnTransformer(transformers=[], remainder=&#39;passthrough&#39;, verbose_feature_names_out=False)</span>\n",
       "\n",
       "        <span class=\"c1\"># preprocessor.transformers.append((&#39;winsorize&#39;, WinsorizerIQR(factor=1.5), NUMERIC_FEATURES))</span>\n",
       "        <span class=\"c1\"># preprocessor.transformers.append((&#39;log_tokens&#39;, log_transformer, LINE_TOKEN_FEATURES))</span>\n",
       "        <span class=\"c1\"># preprocessor.transformers.append((&#39;log_numeric&#39;, log_transformer, NUMERIC_FEATURES))</span>\n",
       "\n",
       "        <span class=\"c1\"># # 3. FIT the preprocessor ONLY on the training data</span>\n",
       "        <span class=\"c1\"># preprocessor.fit(df)</span>\n",
       "        <span class=\"c1\"># df = preprocessor.transform(df)</span>\n",
       "\n",
       "        <span class=\"c1\"># # 4. SAVE the fitted preprocessor</span>\n",
       "        <span class=\"c1\"># # The saved object contains all the calculated Q1, Q3 bounds.</span>\n",
       "        <span class=\"c1\"># joblib.dump(preprocessor, FITTED_PREPROCESSOR)</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_result</span><span class=\"p\">(</span>\n",
       "            <span class=\"s2\">&quot;Detected train subset. Creating new preprocessor...&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">print_to_console</span><span class=\"o\">=</span><span class=\"n\">print_to_console</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"c1\"># code_emb_df = expand_embedding(df, &quot;code_embed&quot;, &quot;code_emb&quot;)</span>\n",
       "        <span class=\"c1\"># msg_emb_df  = expand_embedding(df, &quot;msg_embed&quot;, &quot;msg_emb&quot;)</span>\n",
       "        <span class=\"c1\"># df = pd.concat([df.drop(columns=[&quot;code_embed&quot;, &quot;msg_embed&quot;]), code_emb_df, msg_emb_df], axis=1)</span>\n",
       "\n",
       "        <span class=\"c1\"># Update the EMBEDDINGS constant to reflect the NEW flattened column names</span>\n",
       "        <span class=\"c1\"># FLATTENED_EMBEDDINGS = code_emb_df.columns.tolist() + msg_emb_df.columns.tolist()</span>\n",
       "\n",
       "        <span class=\"c1\"># Define a pipeline for EACH embedding type</span>\n",
       "        <span class=\"c1\"># code_emb_pipe = Pipeline([</span>\n",
       "        <span class=\"c1\">#     (&#39;expand&#39;, EmbeddingExpander(prefix=&quot;code_emb&quot;)),</span>\n",
       "        <span class=\"c1\">#     (&#39;pca&#39;, PCA(n_components=100, random_state=RANDOM_STATE))</span>\n",
       "        <span class=\"c1\"># ])</span>\n",
       "        <span class=\"c1\"># Use it in your pipeline like this:</span>\n",
       "        <span class=\"c1\"># code_emb_pipe = Pipeline(</span>\n",
       "        <span class=\"c1\">#     [</span>\n",
       "        <span class=\"c1\">#         (&quot;expand&quot;, EmbeddingExpander(prefix=&quot;code&quot;)),</span>\n",
       "        <span class=\"c1\">#         (</span>\n",
       "        <span class=\"c1\">#             &quot;pca&quot;,</span>\n",
       "        <span class=\"c1\">#             NamingPCA(</span>\n",
       "        <span class=\"c1\">#                 n_components=10, prefix=&quot;code_emb_&quot;, random_state=RANDOM_STATE</span>\n",
       "        <span class=\"c1\">#             ),</span>\n",
       "        <span class=\"c1\">#         ),</span>\n",
       "        <span class=\"c1\">#     ]</span>\n",
       "        <span class=\"c1\"># )</span>\n",
       "\n",
       "        <span class=\"c1\"># msg_emb_pipe = Pipeline(</span>\n",
       "        <span class=\"c1\">#     [</span>\n",
       "        <span class=\"c1\">#         (&quot;expand&quot;, EmbeddingExpander(prefix=&quot;msg&quot;)),</span>\n",
       "        <span class=\"c1\">#         # (&#39;pca&#39;, PCA(n_components=100, random_state=RANDOM_STATE))</span>\n",
       "        <span class=\"c1\">#         (</span>\n",
       "        <span class=\"c1\">#             &quot;pca&quot;,</span>\n",
       "        <span class=\"c1\">#             NamingPCA(</span>\n",
       "        <span class=\"c1\">#                 n_components=45, prefix=&quot;msg_emb_&quot;, random_state=RANDOM_STATE</span>\n",
       "        <span class=\"c1\">#             ),</span>\n",
       "        <span class=\"c1\">#         ),</span>\n",
       "        <span class=\"c1\">#     ]</span>\n",
       "        <span class=\"c1\"># )</span>\n",
       "\n",
       "        <span class=\"c1\"># # 1. Define a pipeline for numeric features: Winsorize THEN Log</span>\n",
       "        <span class=\"c1\"># numeric_pipeline = Pipeline(</span>\n",
       "        <span class=\"c1\">#     [</span>\n",
       "        <span class=\"c1\">#         (&quot;winsorize&quot;, WinsorizerIQR(factor=1.5)),</span>\n",
       "        <span class=\"c1\">#         (&quot;log&quot;, log_transformer),</span>\n",
       "        <span class=\"c1\">#         (&quot;var_thresh&quot;, VarianceThreshold(threshold=0.0)),</span>\n",
       "        <span class=\"c1\">#     ]</span>\n",
       "        <span class=\"c1\"># )</span>\n",
       "\n",
       "        <span class=\"c1\"># # embedding_transformer = Pipeline(steps=[</span>\n",
       "        <span class=\"c1\"># #     (&quot;pca&quot;, PCA(n_components=100, random_state=RANDOM_STATE))</span>\n",
       "        <span class=\"c1\"># # ])</span>\n",
       "\n",
       "        <span class=\"c1\"># # 2. Setup the ColumnTransformer</span>\n",
       "        <span class=\"c1\"># preprocessor = ColumnTransformer(</span>\n",
       "        <span class=\"c1\">#     transformers=[</span>\n",
       "        <span class=\"c1\">#         # (&#39;num_transformed&#39;, numeric_pipeline, NUMERIC_FEATURES),</span>\n",
       "        <span class=\"c1\">#         # (&#39;token_transformed&#39;, log_transformer, LINE_TOKEN_FEATURES),</span>\n",
       "        <span class=\"c1\">#         # (&quot;embed&quot;, embedding_transformer, FLATTENED_EMBEDDINGS),</span>\n",
       "        <span class=\"c1\">#         (&quot;num&quot;, numeric_pipeline, NUMERIC_FEATURES),</span>\n",
       "        <span class=\"c1\">#         (&quot;tokens&quot;, log_transformer, LINE_TOKEN_FEATURES),</span>\n",
       "        <span class=\"c1\">#         (&quot;code_embed&quot;, code_emb_pipe, [&quot;code_embed&quot;]),  # Pass as list</span>\n",
       "        <span class=\"c1\">#         (&quot;msg_embed&quot;, msg_emb_pipe, [&quot;msg_embed&quot;]),  # Pass as list</span>\n",
       "        <span class=\"c1\">#     ],</span>\n",
       "        <span class=\"c1\">#     remainder=&quot;passthrough&quot;,</span>\n",
       "        <span class=\"c1\">#     verbose_feature_names_out=False,  # This now works because names are unique</span>\n",
       "        <span class=\"c1\"># )</span>\n",
       "\n",
       "        <span class=\"c1\"># transformer_wrapper = TransformerInspector(random_state=random_state)</span>\n",
       "        <span class=\"c1\"># transformer = transformer_wrapper.transformer</span>\n",
       "\n",
       "        <span class=\"c1\"># 3. FIT and TRANSFORM</span>\n",
       "        <span class=\"n\">transformer</span> <span class=\"o\">=</span> <span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"n\">random_state</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"n\">transformer</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">transformer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"c1\"># 4. SAVE</span>\n",
       "        <span class=\"n\">joblib</span><span class=\"o\">.</span><span class=\"n\">dump</span><span class=\"p\">(</span><span class=\"n\">transformer</span><span class=\"p\">,</span> <span class=\"n\">fitted_transformer</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"c1\"># print(&quot;Fitted preprocessor saved to fitted_preprocessor.joblib&quot;)</span>\n",
       "    <span class=\"k\">elif</span> <span class=\"n\">subset</span> <span class=\"ow\">in</span> <span class=\"p\">(</span><span class=\"s2\">&quot;test&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;validate&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_result</span><span class=\"p\">(</span>\n",
       "            <span class=\"s2\">&quot;Detected test subset. Loading fitted preprocessor...&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">print_to_console</span><span class=\"o\">=</span><span class=\"n\">print_to_console</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "        <span class=\"n\">transformer</span><span class=\"p\">:</span> <span class=\"n\">ColumnTransformer</span> <span class=\"o\">=</span> <span class=\"n\">joblib</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">fitted_transformer</span><span class=\"p\">)</span>\n",
       "        <span class=\"c1\"># transformer_wrapper = TransformerInspector(</span>\n",
       "        <span class=\"c1\">#     random_state=random_state, fitted_transformer=transformer_wrapper</span>\n",
       "        <span class=\"c1\"># )</span>\n",
       "        <span class=\"n\">df</span> <span class=\"o\">=</span> <span class=\"n\">transformer</span><span class=\"o\">.</span><span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">df</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">msg</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;Unknown subset value!&quot;</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">ValueError</span><span class=\"p\">(</span><span class=\"n\">msg</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">log_result</span><span class=\"p\">(</span>\n",
       "        <span class=\"s2\">&quot;Transformations applied successfully.&quot;</span><span class=\"p\">,</span> <span class=\"n\">print_to_console</span><span class=\"o\">=</span><span class=\"n\">print_to_console</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">df</span><span class=\"p\">,</span> <span class=\"n\">transformer</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{transform}\\PY{p}{(}\n",
       "    \\PY{n}{df}\\PY{p}{:} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{,}\n",
       "    \\PY{n}{subset}\\PY{p}{:} \\PY{n}{SubsetType}\\PY{p}{,}\n",
       "    \\PY{n}{random\\PYZus{}state}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{,}\n",
       "    \\PY{n}{logger}\\PY{p}{:} \\PY{n}{NotebookLogger} \\PY{o}{=} \\PY{n}{DEF\\PYZus{}NOTEBOOK\\PYZus{}LOGGER}\\PY{p}{,}\n",
       "    \\PY{n}{fitted\\PYZus{}transformer}\\PY{p}{:} \\PY{n}{Path} \\PY{o}{=} \\PY{n}{FITTED\\PYZus{}TRANSFORMER}\\PY{p}{,}\n",
       "    \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{p}{:} \\PY{n+nb}{bool} \\PY{o}{=} \\PY{k+kc}{True}\\PY{p}{,}\n",
       "\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}check}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Performing df transformation...}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "    \\PY{c+c1}{\\PYZsh{} set\\PYZus{}config(transform\\PYZus{}output=\\PYZdq{}pandas\\PYZdq{})}\n",
       "    \\PY{c+c1}{\\PYZsh{} log\\PYZus{}transformer = FunctionTransformer(np.log1p, validate=False)}\n",
       "\n",
       "    \\PY{k}{if} \\PY{n}{subset} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{train}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} log\\PYZus{}check(\\PYZdq{}Detected train subset. Creating new preprocessor...\\PYZdq{}, print\\PYZus{}to\\PYZus{}console=True)}\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor = ColumnTransformer(transformers=[], remainder=\\PYZsq{}passthrough\\PYZsq{}, verbose\\PYZus{}feature\\PYZus{}names\\PYZus{}out=False)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor.transformers.append((\\PYZsq{}winsorize\\PYZsq{}, WinsorizerIQR(factor=1.5), NUMERIC\\PYZus{}FEATURES))}\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor.transformers.append((\\PYZsq{}log\\PYZus{}tokens\\PYZsq{}, log\\PYZus{}transformer, LINE\\PYZus{}TOKEN\\PYZus{}FEATURES))}\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor.transformers.append((\\PYZsq{}log\\PYZus{}numeric\\PYZsq{}, log\\PYZus{}transformer, NUMERIC\\PYZus{}FEATURES))}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} 3. FIT the preprocessor ONLY on the training data}\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor.fit(df)}\n",
       "        \\PY{c+c1}{\\PYZsh{} df = preprocessor.transform(df)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} 4. SAVE the fitted preprocessor}\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} The saved object contains all the calculated Q1, Q3 bounds.}\n",
       "        \\PY{c+c1}{\\PYZsh{} joblib.dump(preprocessor, FITTED\\PYZus{}PREPROCESSOR)}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}result}\\PY{p}{(}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Detected train subset. Creating new preprocessor...}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{o}{=}\\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} code\\PYZus{}emb\\PYZus{}df = expand\\PYZus{}embedding(df, \\PYZdq{}code\\PYZus{}embed\\PYZdq{}, \\PYZdq{}code\\PYZus{}emb\\PYZdq{})}\n",
       "        \\PY{c+c1}{\\PYZsh{} msg\\PYZus{}emb\\PYZus{}df  = expand\\PYZus{}embedding(df, \\PYZdq{}msg\\PYZus{}embed\\PYZdq{}, \\PYZdq{}msg\\PYZus{}emb\\PYZdq{})}\n",
       "        \\PY{c+c1}{\\PYZsh{} df = pd.concat([df.drop(columns=[\\PYZdq{}code\\PYZus{}embed\\PYZdq{}, \\PYZdq{}msg\\PYZus{}embed\\PYZdq{}]), code\\PYZus{}emb\\PYZus{}df, msg\\PYZus{}emb\\PYZus{}df], axis=1)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} Update the EMBEDDINGS constant to reflect the NEW flattened column names}\n",
       "        \\PY{c+c1}{\\PYZsh{} FLATTENED\\PYZus{}EMBEDDINGS = code\\PYZus{}emb\\PYZus{}df.columns.tolist() + msg\\PYZus{}emb\\PYZus{}df.columns.tolist()}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} Define a pipeline for EACH embedding type}\n",
       "        \\PY{c+c1}{\\PYZsh{} code\\PYZus{}emb\\PYZus{}pipe = Pipeline([}\n",
       "        \\PY{c+c1}{\\PYZsh{}     (\\PYZsq{}expand\\PYZsq{}, EmbeddingExpander(prefix=\\PYZdq{}code\\PYZus{}emb\\PYZdq{})),}\n",
       "        \\PY{c+c1}{\\PYZsh{}     (\\PYZsq{}pca\\PYZsq{}, PCA(n\\PYZus{}components=100, random\\PYZus{}state=RANDOM\\PYZus{}STATE))}\n",
       "        \\PY{c+c1}{\\PYZsh{} ])}\n",
       "        \\PY{c+c1}{\\PYZsh{} Use it in your pipeline like this:}\n",
       "        \\PY{c+c1}{\\PYZsh{} code\\PYZus{}emb\\PYZus{}pipe = Pipeline(}\n",
       "        \\PY{c+c1}{\\PYZsh{}     [}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}expand\\PYZdq{}, EmbeddingExpander(prefix=\\PYZdq{}code\\PYZdq{})),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (}\n",
       "        \\PY{c+c1}{\\PYZsh{}             \\PYZdq{}pca\\PYZdq{},}\n",
       "        \\PY{c+c1}{\\PYZsh{}             NamingPCA(}\n",
       "        \\PY{c+c1}{\\PYZsh{}                 n\\PYZus{}components=10, prefix=\\PYZdq{}code\\PYZus{}emb\\PYZus{}\\PYZdq{}, random\\PYZus{}state=RANDOM\\PYZus{}STATE}\n",
       "        \\PY{c+c1}{\\PYZsh{}             ),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         ),}\n",
       "        \\PY{c+c1}{\\PYZsh{}     ]}\n",
       "        \\PY{c+c1}{\\PYZsh{} )}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} msg\\PYZus{}emb\\PYZus{}pipe = Pipeline(}\n",
       "        \\PY{c+c1}{\\PYZsh{}     [}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}expand\\PYZdq{}, EmbeddingExpander(prefix=\\PYZdq{}msg\\PYZdq{})),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         \\PYZsh{} (\\PYZsq{}pca\\PYZsq{}, PCA(n\\PYZus{}components=100, random\\PYZus{}state=RANDOM\\PYZus{}STATE))}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (}\n",
       "        \\PY{c+c1}{\\PYZsh{}             \\PYZdq{}pca\\PYZdq{},}\n",
       "        \\PY{c+c1}{\\PYZsh{}             NamingPCA(}\n",
       "        \\PY{c+c1}{\\PYZsh{}                 n\\PYZus{}components=45, prefix=\\PYZdq{}msg\\PYZus{}emb\\PYZus{}\\PYZdq{}, random\\PYZus{}state=RANDOM\\PYZus{}STATE}\n",
       "        \\PY{c+c1}{\\PYZsh{}             ),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         ),}\n",
       "        \\PY{c+c1}{\\PYZsh{}     ]}\n",
       "        \\PY{c+c1}{\\PYZsh{} )}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} 1. Define a pipeline for numeric features: Winsorize THEN Log}\n",
       "        \\PY{c+c1}{\\PYZsh{} numeric\\PYZus{}pipeline = Pipeline(}\n",
       "        \\PY{c+c1}{\\PYZsh{}     [}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}winsorize\\PYZdq{}, WinsorizerIQR(factor=1.5)),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}log\\PYZdq{}, log\\PYZus{}transformer),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}var\\PYZus{}thresh\\PYZdq{}, VarianceThreshold(threshold=0.0)),}\n",
       "        \\PY{c+c1}{\\PYZsh{}     ]}\n",
       "        \\PY{c+c1}{\\PYZsh{} )}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} embedding\\PYZus{}transformer = Pipeline(steps=[}\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{}     (\\PYZdq{}pca\\PYZdq{}, PCA(n\\PYZus{}components=100, random\\PYZus{}state=RANDOM\\PYZus{}STATE))}\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} ])}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} \\PYZsh{} 2. Setup the ColumnTransformer}\n",
       "        \\PY{c+c1}{\\PYZsh{} preprocessor = ColumnTransformer(}\n",
       "        \\PY{c+c1}{\\PYZsh{}     transformers=[}\n",
       "        \\PY{c+c1}{\\PYZsh{}         \\PYZsh{} (\\PYZsq{}num\\PYZus{}transformed\\PYZsq{}, numeric\\PYZus{}pipeline, NUMERIC\\PYZus{}FEATURES),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         \\PYZsh{} (\\PYZsq{}token\\PYZus{}transformed\\PYZsq{}, log\\PYZus{}transformer, LINE\\PYZus{}TOKEN\\PYZus{}FEATURES),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         \\PYZsh{} (\\PYZdq{}embed\\PYZdq{}, embedding\\PYZus{}transformer, FLATTENED\\PYZus{}EMBEDDINGS),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}num\\PYZdq{}, numeric\\PYZus{}pipeline, NUMERIC\\PYZus{}FEATURES),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}tokens\\PYZdq{}, log\\PYZus{}transformer, LINE\\PYZus{}TOKEN\\PYZus{}FEATURES),}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}code\\PYZus{}embed\\PYZdq{}, code\\PYZus{}emb\\PYZus{}pipe, [\\PYZdq{}code\\PYZus{}embed\\PYZdq{}]),  \\PYZsh{} Pass as list}\n",
       "        \\PY{c+c1}{\\PYZsh{}         (\\PYZdq{}msg\\PYZus{}embed\\PYZdq{}, msg\\PYZus{}emb\\PYZus{}pipe, [\\PYZdq{}msg\\PYZus{}embed\\PYZdq{}]),  \\PYZsh{} Pass as list}\n",
       "        \\PY{c+c1}{\\PYZsh{}     ],}\n",
       "        \\PY{c+c1}{\\PYZsh{}     remainder=\\PYZdq{}passthrough\\PYZdq{},}\n",
       "        \\PY{c+c1}{\\PYZsh{}     verbose\\PYZus{}feature\\PYZus{}names\\PYZus{}out=False,  \\PYZsh{} This now works because names are unique}\n",
       "        \\PY{c+c1}{\\PYZsh{} )}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} transformer\\PYZus{}wrapper = TransformerInspector(random\\PYZus{}state=random\\PYZus{}state)}\n",
       "        \\PY{c+c1}{\\PYZsh{} transformer = transformer\\PYZus{}wrapper.transformer}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} 3. FIT and TRANSFORM}\n",
       "        \\PY{n}{transformer} \\PY{o}{=} \\PY{n}{build}\\PY{p}{(}\\PY{n}{random\\PYZus{}state}\\PY{o}{=}\\PY{n}{random\\PYZus{}state}\\PY{p}{)}\n",
       "\n",
       "        \\PY{n}{transformer}\\PY{o}{.}\\PY{n}{fit}\\PY{p}{(}\\PY{n}{df}\\PY{p}{)}\n",
       "        \\PY{n}{df} \\PY{o}{=} \\PY{n}{transformer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{df}\\PY{p}{)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} 4. SAVE}\n",
       "        \\PY{n}{joblib}\\PY{o}{.}\\PY{n}{dump}\\PY{p}{(}\\PY{n}{transformer}\\PY{p}{,} \\PY{n}{fitted\\PYZus{}transformer}\\PY{p}{)}\n",
       "\n",
       "        \\PY{c+c1}{\\PYZsh{} print(\\PYZdq{}Fitted preprocessor saved to fitted\\PYZus{}preprocessor.joblib\\PYZdq{})}\n",
       "    \\PY{k}{elif} \\PY{n}{subset} \\PY{o+ow}{in} \\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{test}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{validate}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}result}\\PY{p}{(}\n",
       "            \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Detected test subset. Loading fitted preprocessor...}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{o}{=}\\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "        \\PY{n}{transformer}\\PY{p}{:} \\PY{n}{ColumnTransformer} \\PY{o}{=} \\PY{n}{joblib}\\PY{o}{.}\\PY{n}{load}\\PY{p}{(}\\PY{n}{fitted\\PYZus{}transformer}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} transformer\\PYZus{}wrapper = TransformerInspector(}\n",
       "        \\PY{c+c1}{\\PYZsh{}     random\\PYZus{}state=random\\PYZus{}state, fitted\\PYZus{}transformer=transformer\\PYZus{}wrapper}\n",
       "        \\PY{c+c1}{\\PYZsh{} )}\n",
       "        \\PY{n}{df} \\PY{o}{=} \\PY{n}{transformer}\\PY{o}{.}\\PY{n}{transform}\\PY{p}{(}\\PY{n}{df}\\PY{p}{)}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{n}{msg} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Unknown subset value!}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{logger}\\PY{o}{.}\\PY{n}{error}\\PY{p}{(}\\PY{n}{msg}\\PY{p}{)}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{ValueError}\\PY{p}{(}\\PY{n}{msg}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n}{logger}\\PY{o}{.}\\PY{n}{log\\PYZus{}result}\\PY{p}{(}\n",
       "        \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Transformations applied successfully.}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{print\\PYZus{}to\\PYZus{}console}\\PY{o}{=}\\PY{n}{print\\PYZus{}to\\PYZus{}console}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{df}\\PY{p}{,} \\PY{n}{transformer}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "def transform(\n",
       "    df: pd.DataFrame,\n",
       "    subset: SubsetType,\n",
       "    random_state: int,\n",
       "    logger: NotebookLogger = DEF_NOTEBOOK_LOGGER,\n",
       "    fitted_transformer: Path = FITTED_TRANSFORMER,\n",
       "    print_to_console: bool = True,\n",
       "):\n",
       "    logger.log_check(\"Performing df transformation...\")\n",
       "    # set_config(transform_output=\"pandas\")\n",
       "    # log_transformer = FunctionTransformer(np.log1p, validate=False)\n",
       "\n",
       "    if subset == \"train\":\n",
       "        # log_check(\"Detected train subset. Creating new preprocessor...\", print_to_console=True)\n",
       "        # preprocessor = ColumnTransformer(transformers=[], remainder='passthrough', verbose_feature_names_out=False)\n",
       "\n",
       "        # preprocessor.transformers.append(('winsorize', WinsorizerIQR(factor=1.5), NUMERIC_FEATURES))\n",
       "        # preprocessor.transformers.append(('log_tokens', log_transformer, LINE_TOKEN_FEATURES))\n",
       "        # preprocessor.transformers.append(('log_numeric', log_transformer, NUMERIC_FEATURES))\n",
       "\n",
       "        # # 3. FIT the preprocessor ONLY on the training data\n",
       "        # preprocessor.fit(df)\n",
       "        # df = preprocessor.transform(df)\n",
       "\n",
       "        # # 4. SAVE the fitted preprocessor\n",
       "        # # The saved object contains all the calculated Q1, Q3 bounds.\n",
       "        # joblib.dump(preprocessor, FITTED_PREPROCESSOR)\n",
       "        logger.log_result(\n",
       "            \"Detected train subset. Creating new preprocessor...\",\n",
       "            print_to_console=print_to_console,\n",
       "        )\n",
       "\n",
       "        # code_emb_df = expand_embedding(df, \"code_embed\", \"code_emb\")\n",
       "        # msg_emb_df  = expand_embedding(df, \"msg_embed\", \"msg_emb\")\n",
       "        # df = pd.concat([df.drop(columns=[\"code_embed\", \"msg_embed\"]), code_emb_df, msg_emb_df], axis=1)\n",
       "\n",
       "        # Update the EMBEDDINGS constant to reflect the NEW flattened column names\n",
       "        # FLATTENED_EMBEDDINGS = code_emb_df.columns.tolist() + msg_emb_df.columns.tolist()\n",
       "\n",
       "        # Define a pipeline for EACH embedding type\n",
       "        # code_emb_pipe = Pipeline([\n",
       "        #     ('expand', EmbeddingExpander(prefix=\"code_emb\")),\n",
       "        #     ('pca', PCA(n_components=100, random_state=RANDOM_STATE))\n",
       "        # ])\n",
       "        # Use it in your pipeline like this:\n",
       "        # code_emb_pipe = Pipeline(\n",
       "        #     [\n",
       "        #         (\"expand\", EmbeddingExpander(prefix=\"code\")),\n",
       "        #         (\n",
       "        #             \"pca\",\n",
       "        #             NamingPCA(\n",
       "        #                 n_components=10, prefix=\"code_emb_\", random_state=RANDOM_STATE\n",
       "        #             ),\n",
       "        #         ),\n",
       "        #     ]\n",
       "        # )\n",
       "\n",
       "        # msg_emb_pipe = Pipeline(\n",
       "        #     [\n",
       "        #         (\"expand\", EmbeddingExpander(prefix=\"msg\")),\n",
       "        #         # ('pca', PCA(n_components=100, random_state=RANDOM_STATE))\n",
       "        #         (\n",
       "        #             \"pca\",\n",
       "        #             NamingPCA(\n",
       "        #                 n_components=45, prefix=\"msg_emb_\", random_state=RANDOM_STATE\n",
       "        #             ),\n",
       "        #         ),\n",
       "        #     ]\n",
       "        # )\n",
       "\n",
       "        # # 1. Define a pipeline for numeric features: Winsorize THEN Log\n",
       "        # numeric_pipeline = Pipeline(\n",
       "        #     [\n",
       "        #         (\"winsorize\", WinsorizerIQR(factor=1.5)),\n",
       "        #         (\"log\", log_transformer),\n",
       "        #         (\"var_thresh\", VarianceThreshold(threshold=0.0)),\n",
       "        #     ]\n",
       "        # )\n",
       "\n",
       "        # # embedding_transformer = Pipeline(steps=[\n",
       "        # #     (\"pca\", PCA(n_components=100, random_state=RANDOM_STATE))\n",
       "        # # ])\n",
       "\n",
       "        # # 2. Setup the ColumnTransformer\n",
       "        # preprocessor = ColumnTransformer(\n",
       "        #     transformers=[\n",
       "        #         # ('num_transformed', numeric_pipeline, NUMERIC_FEATURES),\n",
       "        #         # ('token_transformed', log_transformer, LINE_TOKEN_FEATURES),\n",
       "        #         # (\"embed\", embedding_transformer, FLATTENED_EMBEDDINGS),\n",
       "        #         (\"num\", numeric_pipeline, NUMERIC_FEATURES),\n",
       "        #         (\"tokens\", log_transformer, LINE_TOKEN_FEATURES),\n",
       "        #         (\"code_embed\", code_emb_pipe, [\"code_embed\"]),  # Pass as list\n",
       "        #         (\"msg_embed\", msg_emb_pipe, [\"msg_embed\"]),  # Pass as list\n",
       "        #     ],\n",
       "        #     remainder=\"passthrough\",\n",
       "        #     verbose_feature_names_out=False,  # This now works because names are unique\n",
       "        # )\n",
       "\n",
       "        # transformer_wrapper = TransformerInspector(random_state=random_state)\n",
       "        # transformer = transformer_wrapper.transformer\n",
       "\n",
       "        # 3. FIT and TRANSFORM\n",
       "        transformer = build(random_state=random_state)\n",
       "\n",
       "        transformer.fit(df)\n",
       "        df = transformer.transform(df)\n",
       "\n",
       "        # 4. SAVE\n",
       "        joblib.dump(transformer, fitted_transformer)\n",
       "\n",
       "        # print(\"Fitted preprocessor saved to fitted_preprocessor.joblib\")\n",
       "    elif subset in (\"test\", \"validate\"):\n",
       "        logger.log_result(\n",
       "            \"Detected test subset. Loading fitted preprocessor...\",\n",
       "            print_to_console=print_to_console,\n",
       "        )\n",
       "        transformer: ColumnTransformer = joblib.load(fitted_transformer)\n",
       "        # transformer_wrapper = TransformerInspector(\n",
       "        #     random_state=random_state, fitted_transformer=transformer_wrapper\n",
       "        # )\n",
       "        df = transformer.transform(df)\n",
       "    else:\n",
       "        msg = \"Unknown subset value!\"\n",
       "        logger.logger.error(msg)\n",
       "        raise ValueError(msg)\n",
       "\n",
       "    logger.log_result(\n",
       "        \"Transformations applied successfully.\", print_to_console=print_to_console\n",
       "    )\n",
       "\n",
       "    return df, transformer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def expand_embedding(df, col_name, prefix):\n",
    "#     # Converts a column of arrays into a matrix\n",
    "#     emb = np.vstack(df[col_name].values)\n",
    "#     emb_df = pd.DataFrame(\n",
    "#         emb,\n",
    "#         index=df.index,\n",
    "#         columns=[f\"{prefix}_{i}\" for i in range(emb.shape[1])]\n",
    "#     )\n",
    "#     return emb_df\n",
    "display_func(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b487378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Performing df transformation...\n",
      "[PREPROCESSING RESULT] Detected test subset. Loading fitted preprocessor...\n",
      "[PREPROCESSING RESULT] Transformations applied successfully.\n"
     ]
    }
   ],
   "source": [
    "df, transformer = transform(df=df,\n",
    "        subset=subset,\n",
    "          logger=logger,\n",
    "          random_state=RANDOM_STATE,\n",
    "          fitted_transformer=FITTED_TRANSFORMER)\n",
    "\n",
    "# fitted_transfomer: ColumnTransformer = joblib.load(FITTED_TRANSFORMER)\n",
    "\n",
    "\n",
    "# set_config(transform_output='pandas')\n",
    "# log_transformer = FunctionTransformer(np.log1p, validate=False)\n",
    "\n",
    "# if subset == 'train':\n",
    "#     # log_check(\"Detected train subset. Creating new preprocessor...\", print_to_console=True)\n",
    "#     # preprocessor = ColumnTransformer(transformers=[], remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "#     # preprocessor.transformers.append(('winsorize', WinsorizerIQR(factor=1.5), NUMERIC_FEATURES))\n",
    "#     # preprocessor.transformers.append(('log_tokens', log_transformer, LINE_TOKEN_FEATURES))\n",
    "#     # preprocessor.transformers.append(('log_numeric', log_transformer, NUMERIC_FEATURES))\n",
    "\n",
    "#     # # 3. FIT the preprocessor ONLY on the training data\n",
    "#     # preprocessor.fit(df)\n",
    "#     # df = preprocessor.transform(df)\n",
    "\n",
    "#     # # 4. SAVE the fitted preprocessor\n",
    "#     # # The saved object contains all the calculated Q1, Q3 bounds.\n",
    "#     # joblib.dump(preprocessor, FITTED_PREPROCESSOR)\n",
    "#     log_check(\"Detected train subset. Creating new preprocessor...\", print_to_console=True)\n",
    "\n",
    "#     # code_emb_df = expand_embedding(df, \"code_embed\", \"code_emb\")\n",
    "#     # msg_emb_df  = expand_embedding(df, \"msg_embed\", \"msg_emb\")\n",
    "#     # df = pd.concat([df.drop(columns=[\"code_embed\", \"msg_embed\"]), code_emb_df, msg_emb_df], axis=1)\n",
    "\n",
    "#     # Update the EMBEDDINGS constant to reflect the NEW flattened column names\n",
    "#     # FLATTENED_EMBEDDINGS = code_emb_df.columns.tolist() + msg_emb_df.columns.tolist()\n",
    "\n",
    "#     # Define a pipeline for EACH embedding type\n",
    "#     # code_emb_pipe = Pipeline([\n",
    "#     #     ('expand', EmbeddingExpander(prefix=\"code_emb\")),\n",
    "#     #     ('pca', PCA(n_components=100, random_state=RANDOM_STATE))\n",
    "#     # ])\n",
    "#     # Use it in your pipeline like this:\n",
    "#     code_emb_pipe = Pipeline([\n",
    "#         ('expand', EmbeddingExpander(prefix=\"code\")),\n",
    "#         ('pca', NamingPCA(n_components=10, prefix=\"code_emb_\", random_state=RANDOM_STATE))\n",
    "#     ])\n",
    "\n",
    "#     msg_emb_pipe = Pipeline([\n",
    "#         ('expand', EmbeddingExpander(prefix=\"msg\")),\n",
    "#         # ('pca', PCA(n_components=100, random_state=RANDOM_STATE))\n",
    "#         ('pca', NamingPCA(n_components=45, prefix=\"msg_emb_\", random_state=RANDOM_STATE))\n",
    "\n",
    "#     ])\n",
    "\n",
    "#     # 1. Define a pipeline for numeric features: Winsorize THEN Log\n",
    "#     numeric_pipeline = Pipeline([\n",
    "#         ('winsorize', WinsorizerIQR(factor=1.5)),\n",
    "#         ('log', log_transformer),\n",
    "#         (\"var_thresh\", VarianceThreshold(threshold=0.0))\n",
    "#     ])\n",
    "\n",
    "#     # embedding_transformer = Pipeline(steps=[\n",
    "#     #     (\"pca\", PCA(n_components=100, random_state=RANDOM_STATE))\n",
    "#     # ])\n",
    "\n",
    "\n",
    "#     # 2. Setup the ColumnTransformer\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             # ('num_transformed', numeric_pipeline, NUMERIC_FEATURES),\n",
    "#             # ('token_transformed', log_transformer, LINE_TOKEN_FEATURES),\n",
    "#             # (\"embed\", embedding_transformer, FLATTENED_EMBEDDINGS),\n",
    "#             ('num', numeric_pipeline, NUMERIC_FEATURES),\n",
    "#             ('tokens', log_transformer, LINE_TOKEN_FEATURES),\n",
    "#             ('code_embed', code_emb_pipe, ['code_embed']), # Pass as list\n",
    "#             ('msg_embed', msg_emb_pipe, ['msg_embed']),    # Pass as list\n",
    "#         ],\n",
    "#         remainder='passthrough',\n",
    "#         verbose_feature_names_out=False  # This now works because names are unique\n",
    "#     )\n",
    "\n",
    "#     # 3. FIT and TRANSFORM\n",
    "#     preprocessor.fit(df)\n",
    "#     df = preprocessor.transform(df)\n",
    "\n",
    "#     # 4. SAVE\n",
    "#     joblib.dump(preprocessor, FITTED_TRANSFORMER)\n",
    "\n",
    "#     # print(\"Fitted preprocessor saved to fitted_preprocessor.joblib\")\n",
    "# elif subset in ('test', 'validate'):\n",
    "#     log_check(\"Detected test subset. Loading fitted preprocessor...\", print_to_console=True)\n",
    "#     loaded_preprocessor = joblib.load(FITTED_TRANSFORMER)\n",
    "#     df = loaded_preprocessor.transform(df)\n",
    "# else:\n",
    "#     msg = \"Unknown subset value!\"\n",
    "#     logger.error(msg)\n",
    "#     raise ValueError(msg)\n",
    "\n",
    "\n",
    "# log_result(\"Transformations applied successfully.\", print_to_console=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     (\"var_thresh\", VarianceThreshold(threshold=0.0))\n",
    "# ])\n",
    "\n",
    "# embedding_transformer = Pipeline(steps=[\n",
    "#     (\"pca\", PCA(n_components=100, random_state=RANDOM_STATE))\n",
    "# ])\n",
    "\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # (\"struct\", \"passthrough\", structured_features),\n",
    "#         (\"struct\", numeric_transformer, structured_features),\n",
    "#         (\"embed\", embedding_transformer, embedding_features),\n",
    "#     ],\n",
    "#     remainder=\"drop\"\n",
    "# )\n",
    "\n",
    "# def winsorize_iqr(df, col, preserve_original: bool = False):\n",
    "#     \"\"\"\n",
    "#     Caps extreme outliers using IQR fences.\n",
    "#     Keeps the distribution shape mostly intact.\n",
    "#     \"\"\"\n",
    "#     Q1 = df[col].quantile(0.25)\n",
    "#     Q3 = df[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower = Q1 - 1.5 * IQR\n",
    "#     upper = Q3 + 1.5 * IQR\n",
    "\n",
    "#     print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "#     new_col_name = col + \"_winsorized\" if preserve_original else col\n",
    "\n",
    "#     df[new_col_name] = df[col].clip(lower=lower, upper=upper)\n",
    "#     print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# --- Apply to all numeric columns ---\n",
    "# for col in NUMERIC_FEATURES:\n",
    "#     df = winsorize_iqr(df, col, preserve_original=True) if col == 'recent_churn' else winsorize_iqr(df, col)\n",
    "\n",
    "# for col in LINE_TOKEN_FEATURES:\n",
    "#     # df = winsorize_iqr(df, col)\n",
    "#     df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e9fda",
   "metadata": {},
   "source": [
    "#### 5.2.2.3 - Variance Explanation of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd2d49bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-CodeCell .highlight,\n",
       ".output pre,\n",
       ".output code {\n",
       "    background-color: #111111 !important;\n",
       "    color: #94d4d4 !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">pca_explained_variance</span><span class=\"p\">(</span><span class=\"n\">transformer</span><span class=\"p\">:</span> <span class=\"n\">ColumnTransformer</span><span class=\"p\">,</span> <span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">float</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">    Return total explained variance ratio for a PCA step</span>\n",
       "<span class=\"sd\">    inside a named ColumnTransformer sub-pipeline.</span>\n",
       "\n",
       "<span class=\"sd\">    Parameters</span>\n",
       "<span class=\"sd\">    ----------</span>\n",
       "<span class=\"sd\">    name : str</span>\n",
       "<span class=\"sd\">        Name of the transformer in ColumnTransformer</span>\n",
       "<span class=\"sd\">        (e.g. &#39;code_embed&#39;, &#39;msg_embed&#39;)</span>\n",
       "\n",
       "<span class=\"sd\">    Returns</span>\n",
       "<span class=\"sd\">    -------</span>\n",
       "<span class=\"sd\">    float</span>\n",
       "<span class=\"sd\">        Sum of explained variance ratios</span>\n",
       "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">transformer</span><span class=\"p\">,</span> <span class=\"s2\">&quot;named_transformers_&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">(</span><span class=\"s2\">&quot;Transformer must be fitted before accessing PCA info.&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">try</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">pca</span> <span class=\"o\">=</span> <span class=\"n\">transformer</span><span class=\"o\">.</span><span class=\"n\">named_transformers_</span><span class=\"p\">[</span><span class=\"n\">name</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">named_steps</span><span class=\"p\">[</span><span class=\"s2\">&quot;pca&quot;</span><span class=\"p\">]</span>\n",
       "    <span class=\"k\">except</span> <span class=\"ne\">KeyError</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">KeyError</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;No PCA found under transformer &#39;</span><span class=\"si\">{</span><span class=\"n\">name</span><span class=\"si\">}</span><span class=\"s2\">&#39;&quot;</span><span class=\"p\">)</span> <span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">e</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">pca</span><span class=\"o\">.</span><span class=\"n\">explained_variance_ratio_</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">())</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{pca\\PYZus{}explained\\PYZus{}variance}\\PY{p}{(}\\PY{n}{transformer}\\PY{p}{:} \\PY{n}{ColumnTransformer}\\PY{p}{,} \\PY{n}{name}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{float}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{    Return total explained variance ratio for a PCA step}\n",
       "\\PY{l+s+sd}{    inside a named ColumnTransformer sub\\PYZhy{}pipeline.}\n",
       "\n",
       "\\PY{l+s+sd}{    Parameters}\n",
       "\\PY{l+s+sd}{    \\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}}\n",
       "\\PY{l+s+sd}{    name : str}\n",
       "\\PY{l+s+sd}{        Name of the transformer in ColumnTransformer}\n",
       "\\PY{l+s+sd}{        (e.g. \\PYZsq{}code\\PYZus{}embed\\PYZsq{}, \\PYZsq{}msg\\PYZus{}embed\\PYZsq{})}\n",
       "\n",
       "\\PY{l+s+sd}{    Returns}\n",
       "\\PY{l+s+sd}{    \\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}\\PYZhy{}}\n",
       "\\PY{l+s+sd}{    float}\n",
       "\\PY{l+s+sd}{        Sum of explained variance ratios}\n",
       "\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{if} \\PY{o+ow}{not} \\PY{n+nb}{hasattr}\\PY{p}{(}\\PY{n}{transformer}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{named\\PYZus{}transformers\\PYZus{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{RuntimeError}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Transformer must be fitted before accessing PCA info.}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{try}\\PY{p}{:}\n",
       "        \\PY{n}{pca} \\PY{o}{=} \\PY{n}{transformer}\\PY{o}{.}\\PY{n}{named\\PYZus{}transformers\\PYZus{}}\\PY{p}{[}\\PY{n}{name}\\PY{p}{]}\\PY{o}{.}\\PY{n}{named\\PYZus{}steps}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{pca}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\n",
       "    \\PY{k}{except} \\PY{n+ne}{KeyError} \\PY{k}{as} \\PY{n}{e}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{KeyError}\\PY{p}{(}\\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{No PCA found under transformer }\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{name}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)} \\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{e}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n+nb}{float}\\PY{p}{(}\\PY{n}{pca}\\PY{o}{.}\\PY{n}{explained\\PYZus{}variance\\PYZus{}ratio\\PYZus{}}\\PY{o}{.}\\PY{n}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "def pca_explained_variance(transformer: ColumnTransformer, name: str) -> float:\n",
       "    \"\"\"\n",
       "    Return total explained variance ratio for a PCA step\n",
       "    inside a named ColumnTransformer sub-pipeline.\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    name : str\n",
       "        Name of the transformer in ColumnTransformer\n",
       "        (e.g. 'code_embed', 'msg_embed')\n",
       "\n",
       "    Returns\n",
       "    -------\n",
       "    float\n",
       "        Sum of explained variance ratios\n",
       "    \"\"\"\n",
       "    if not hasattr(transformer, \"named_transformers_\"):\n",
       "        raise RuntimeError(\"Transformer must be fitted before accessing PCA info.\")\n",
       "\n",
       "    try:\n",
       "        pca = transformer.named_transformers_[name].named_steps[\"pca\"]\n",
       "    except KeyError as e:\n",
       "        raise KeyError(f\"No PCA found under transformer '{name}'\") from e\n",
       "\n",
       "    return float(pca.explained_variance_ratio_.sum())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_func(pca_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b30dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Checking explanation of variance by embeddings...\n",
      "[PREPROCESSING RESULT] Code embeddings explain 85.40% of variance\n",
      "[PREPROCESSING RESULT] Message embeddings explain 82.61% of variance\n"
     ]
    }
   ],
   "source": [
    "# Access the PCA step from your fitted preprocessor\n",
    "# Assuming the step was named 'code_pca' in the ColumnTransformer\n",
    "# pca_model = fitted_transfomer.named_transformers_['code_embed'].named_steps['pca']\n",
    "# total_variance = sum(pca_model.explained_variance_ratio_)\n",
    "\n",
    "# print(f\"Your 50 components explain {total_variance:.2%} of the original code data.\")\n",
    "\n",
    "# pca_model = fitted_transfomer.named_transformers_['msg_embed'].named_steps['pca']\n",
    "# total_variance = sum(pca_model.explained_variance_ratio_)\n",
    "# print(f\"Your 50 components explain {total_variance:.2%} of the original msg data.\")\n",
    "\n",
    "# from src_code.ml_pipeline.preprocessing.transformers import pca_explained_variance\n",
    "\n",
    "logger.log_check(\"Checking explanation of variance by embeddings...\")\n",
    "\n",
    "\n",
    "logger.log_result(\n",
    "    f\"Code embeddings explain \"\n",
    "    f\"{pca_explained_variance(transformer=transformer, name='code_embed'):.2%} of variance\"\n",
    ")\n",
    "\n",
    "logger.log_result(\n",
    "    f\"Message embeddings explain \"\n",
    "    f\"{pca_explained_variance(transformer=transformer, name='msg_embed'):.2%} of variance\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4cf37",
   "metadata": {},
   "source": [
    "<!-- ### 5.2.2 - Fix negative values before log transform\n",
    "Some features (e.g., time_since_last_change) contain negative values.\n",
    "\n",
    "We shift them to be â‰¥ 0 before applying log1p: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0151761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def shift_min_to_zero(df, col):\n",
    "# #     \"\"\"Shift column so minimum is 0 if negative values exist.\"\"\"\n",
    "# #     min_val = df[col].min()\n",
    "# #     if min_val < 0:\n",
    "# #         df[col] = df[col] - min_val\n",
    "# #     return df\n",
    "\n",
    "# # for col in NUMERIC_FEATURES:\n",
    "# #     df = shift_min_to_zero(df, col)\n",
    "\n",
    "# from notebooks.utils import contains_negative\n",
    "# from notebooks.constants import NUMERIC_FEATURES\n",
    "\n",
    "# NEG_FEATURES_TO_DROP = ['time_since_last_change']\n",
    "\n",
    "# # List of features to check: NUMERIC_FEATURES excluding NEG_FEATURES_TO_DROP\n",
    "# features_to_check = [\n",
    "#     col for col in NUMERIC_FEATURES \n",
    "#     if col not in NEG_FEATURES_TO_DROP\n",
    "# ]\n",
    "\n",
    "# # Check if any of the features in features_to_check contain negative values\n",
    "# if any(contains_negative(df, col) for col in features_to_check):\n",
    "#     # If True, raise an exception\n",
    "#     raise ValueError(\"Unexpected negative values found in one or more numeric features that are NOT set to be dropped.\")\n",
    "\n",
    "\n",
    "# neg_mask = df[\"time_since_last_change\"] < 0\n",
    "# n_neg = neg_mask.sum()\n",
    "\n",
    "# print(f\"Dropping {n_neg} rows with negative time_since_last_change\")\n",
    "\n",
    "# df = df[~neg_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec505e",
   "metadata": {},
   "source": [
    "### 5.2.3 - Log1p Transformation\n",
    "Reduces heavy right-skew (your EDA showed skews up to 100+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6892df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in NUMERIC_FEATURES:\n",
    "#     df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a70b5",
   "metadata": {},
   "source": [
    "## 5.3. - Save preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bbcbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Saving the preprocessed dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING RESULT] Preprocessed dataset saved to C:\\Users\\fmojt\\Code\\DPThesis\\DP_Thesis\\data\\processed\\test_preprocessed.feather\n"
     ]
    }
   ],
   "source": [
    "# log_check(\"Saving the preprocessed dataset...\", print_to_console=True)\n",
    "\n",
    "# OUTPUT_PATH = PREPROCESSING_MAPPINGS[subset]['output']\n",
    "\n",
    "# # 1. Get the names of the final features\n",
    "# # feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# # 2. Reconstruct the DataFrame\n",
    "# # df_transformed = pd.DataFrame(df, columns=feature_names)\n",
    "\n",
    "# df.to_feather(OUTPUT_PATH)\n",
    "\n",
    "# log_result(f\"Preprocessed dataset saved to {OUTPUT_PATH}\", print_to_console=True)\n",
    "\n",
    "save_df(df=df, df_file_path=PREPROCESSING_MAPPINGS[subset][\"output\"], logger=logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP_Thesis-sh7Ft33M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
