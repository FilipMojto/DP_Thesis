{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262d8bc5",
   "metadata": {},
   "source": [
    "# 05 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9bacf",
   "metadata": {},
   "source": [
    "## 5.1 - Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63351fa",
   "metadata": {},
   "source": [
    "### 5.1.1 - Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ebf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_config import setup_notebook_logging\n",
    "\n",
    "logger, log_start, log_check, log_result = setup_notebook_logging(label=\"PREPROCESSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39586ea7",
   "metadata": {},
   "source": [
    "### 5.1.2 Configuring Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7596c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Setting up root by appending the parent to the sys...\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Setting up root by appending the parent to the sys...\", print_to_console=True)\n",
    "from jupyter_init import setup\n",
    "\n",
    "setup()\n",
    "\n",
    "from src_code.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106823f",
   "metadata": {},
   "source": [
    "### 5.1.3 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a551fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREPROCESSING CHECK] Loading the dataset...\n",
      "[PREPROCESSING RESULT] Loaded dataframe with 133273 rows and 31 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Loading the dataset...\", print_to_console=True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ---- LOAD ----\n",
    "df = pd.read_feather(EXTRATED_TRAIN_DF_FILE)\n",
    "log_result(f\"Loaded dataframe with {len(df)} rows and {len(df.columns)} columns\\n\", print_to_console=True)\n",
    "\n",
    "# For large datasets\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cc3abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    133273.000000\n",
       "mean          0.152326\n",
       "std           2.480067\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max         108.000000\n",
       "Name: todo, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['todo'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963d811",
   "metadata": {},
   "source": [
    "## 5.2 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8f4ea",
   "metadata": {},
   "source": [
    "### 5.2.1 - Winsorization (IQR-base)\n",
    "\n",
    "Applies the same bounds your EDA used.\n",
    "\n",
    "You want preprocessing to match your EDA findings, so we clamp values to the lower/upper fences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b487378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df len before winsorization (author_exp_pre): 133273\n",
      "Df len before winsorization (author_exp_pre): 133273\n",
      "Df len before winsorization (author_recent_activity_pre): 133273\n",
      "Df len before winsorization (author_recent_activity_pre): 133273\n",
      "Df len before winsorization (loc_added): 133273\n",
      "Df len before winsorization (loc_added): 133273\n",
      "Df len before winsorization (loc_deleted): 133273\n",
      "Df len before winsorization (loc_deleted): 133273\n",
      "Df len before winsorization (files_changed): 133273\n",
      "Df len before winsorization (files_changed): 133273\n",
      "Df len before winsorization (hunks_count): 133273\n",
      "Df len before winsorization (hunks_count): 133273\n",
      "Df len before winsorization (msg_len): 133273\n",
      "Df len before winsorization (msg_len): 133273\n",
      "Df len before winsorization (ast_delta): 133273\n",
      "Df len before winsorization (ast_delta): 133273\n",
      "Df len before winsorization (complexity_delta): 133273\n",
      "Df len before winsorization (complexity_delta): 133273\n",
      "Df len before winsorization (max_func_change): 133273\n",
      "Df len before winsorization (max_func_change): 133273\n",
      "Df len before winsorization (time_since_last_change): 133273\n",
      "Df len before winsorization (time_since_last_change): 133273\n",
      "Df len before winsorization (recent_churn): 133273\n",
      "Df len before winsorization (recent_churn): 133273\n"
     ]
    }
   ],
   "source": [
    "from notebooks.constants import NUMERIC_FEATURES, LINE_TOKEN_FEATURES\n",
    "\n",
    "\n",
    "def winsorize_iqr(df, col, preserve_original: bool = False):\n",
    "    \"\"\"\n",
    "    Caps extreme outliers using IQR fences.\n",
    "    Keeps the distribution shape mostly intact.\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "    new_col_name = col + \"_winsorized\" if preserve_original else col\n",
    "\n",
    "    df[new_col_name] = df[col].clip(lower=lower, upper=upper)\n",
    "    print(f\"Df len before winsorization ({col}): {len(df)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Apply to all numeric columns ---\n",
    "for col in NUMERIC_FEATURES:\n",
    "    df = winsorize_iqr(df, col, preserve_original=True) if col == 'recent_churn' else winsorize_iqr(df, col)\n",
    "\n",
    "for col in LINE_TOKEN_FEATURES:\n",
    "    # df = winsorize_iqr(df, col)\n",
    "    df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    133273.000000\n",
       "mean          0.054613\n",
       "std           0.250436\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           4.691348\n",
       "Name: todo, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['todo'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4cf37",
   "metadata": {},
   "source": [
    "### 5.2.2 - Fix negative values before log transform\n",
    "Some features (e.g., time_since_last_change) contain negative values.\n",
    "\n",
    "We shift them to be â‰¥ 0 before applying log1p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0151761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 66 rows with negative time_since_last_change\n"
     ]
    }
   ],
   "source": [
    "# def shift_min_to_zero(df, col):\n",
    "#     \"\"\"Shift column so minimum is 0 if negative values exist.\"\"\"\n",
    "#     min_val = df[col].min()\n",
    "#     if min_val < 0:\n",
    "#         df[col] = df[col] - min_val\n",
    "#     return df\n",
    "\n",
    "# for col in NUMERIC_FEATURES:\n",
    "#     df = shift_min_to_zero(df, col)\n",
    "\n",
    "from notebooks.utils import contains_negative\n",
    "from notebooks.constants import NUMERIC_FEATURES\n",
    "\n",
    "NEG_FEATURES_TO_DROP = ['time_since_last_change']\n",
    "\n",
    "# List of features to check: NUMERIC_FEATURES excluding NEG_FEATURES_TO_DROP\n",
    "features_to_check = [\n",
    "    col for col in NUMERIC_FEATURES \n",
    "    if col not in NEG_FEATURES_TO_DROP\n",
    "]\n",
    "\n",
    "# Check if any of the features in features_to_check contain negative values\n",
    "if any(contains_negative(df, col) for col in features_to_check):\n",
    "    # If True, raise an exception\n",
    "    raise ValueError(\"Unexpected negative values found in one or more numeric features that are NOT set to be dropped.\")\n",
    "\n",
    "\n",
    "neg_mask = df[\"time_since_last_change\"] < 0\n",
    "n_neg = neg_mask.sum()\n",
    "\n",
    "print(f\"Dropping {n_neg} rows with negative time_since_last_change\")\n",
    "\n",
    "df = df[~neg_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec505e",
   "metadata": {},
   "source": [
    "### 5.2.3 - Log1p Transformation\n",
    "Reduces heavy right-skew (your EDA showed skews up to 100+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6892df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in NUMERIC_FEATURES:\n",
    "    df[col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a70b5",
   "metadata": {},
   "source": [
    "## 5.3. - Save preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to C:\\Users\\fmojt\\Code\\Software Projects\\DiplomaThesis\\data\\preprocessed\\train_preprocessed.feather\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "OUTPUT_PATH = PROCESSED_DATA_DIR / \"train_preprocessed.feather\"\n",
    "df.to_feather(OUTPUT_PATH)\n",
    "\n",
    "print(f\"Preprocessed dataset saved to {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src_code-O5IEtaYk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
