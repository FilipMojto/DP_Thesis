{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e271e2",
   "metadata": {},
   "source": [
    "# 06 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c840060a",
   "metadata": {},
   "source": [
    "## 6.1 - Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac819a1",
   "metadata": {},
   "source": [
    "### 6.1.1 Setting Up Project Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4d4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info(\"Setting up root by appending the parent to the sys...\")\n",
    "from jupyter_init import setup\n",
    "\n",
    "setup()\n",
    "\n",
    "from src_code.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27473490",
   "metadata": {},
   "source": [
    "### 6.1.2 Setting Up Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcadee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Starting notebook: 06-feature-engineering (Session 135) ==================\n",
      "[ENGINEERING RESULT] Logging configured.\n"
     ]
    }
   ],
   "source": [
    "from notebooks.logging_config import setup_notebook_logging\n",
    "\n",
    "logger, log_start, log_check, log_result = setup_notebook_logging(label=\"ENGINEERING\")\n",
    "\n",
    "log_start(print_to_console=True)\n",
    "log_result(\"Logging configured.\", print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30bd10",
   "metadata": {},
   "source": [
    "### 6.1.3 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c38c618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENGINEERING CHECK] Loading the dataset...\n",
      "[ENGINEERING RESULT] Loaded dataframe with 139545 rows and 229 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_check(\"Loading the dataset...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "SUBSET: SubsetType = 'train'\n",
    "# TRANSFORMED_DF = EXTRACTED_DATA_DIR / \"test_labeled_features_partial_copy.feather\"\n",
    "# DF = PROCESSED_DATA_DIR / \"train_preprocessed.feather\"\n",
    "DF_PATH = ENGINEERING_MAPPINGS[SUBSET]['input']\n",
    "\n",
    "# ---- LOAD ----\n",
    "df = pd.read_feather(DF_PATH)\n",
    "msg = f\"Loaded dataframe with {len(df)} rows and {len(df.columns)} columns\\n\"\n",
    "# print(msg)\n",
    "log_result(msg, print_to_console=True)\n",
    "\n",
    "# For large datasets\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ac5a6",
   "metadata": {},
   "source": [
    "## 6.2 - Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a068d3a",
   "metadata": {},
   "source": [
    "### 6.2.1 - Create interaction / derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49420299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: churn ratio\n",
    "if \"loc_added\" in df.columns and \"loc_deleted\" in df.columns:\n",
    "    df[\"loc_churn_ratio\"] = df[\"loc_added\"] / (df[\"loc_deleted\"] + 1)  # avoid division by zero\n",
    "\n",
    "# Example: recent activity per experience\n",
    "if \"author_recent_activity_pre\" in df.columns and \"author_exp_pre\" in df.columns:\n",
    "    df[\"activity_per_exp\"] = df[\"author_recent_activity_pre\"] / (df[\"author_exp_pre\"] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b7e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author_exp_pre', 'author_recent_activity_pre', 'loc_added',\n",
       "       'loc_deleted', 'files_changed', 'hunks_count', 'msg_len', 'ast_delta',\n",
       "       'complexity_delta', 'max_func_change',\n",
       "       ...\n",
       "       'content', 'methods', 'lines', 'author_email', 'canonical_datetime',\n",
       "       'label', 'has_fix_kw', 'has_bug_kw', 'loc_churn_ratio',\n",
       "       'activity_per_exp'],\n",
       "      dtype='object', length=231)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624167b3",
   "metadata": {},
   "source": [
    "### 6.2.2 - Binning / categorical transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f86945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: bucket commits by size\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from notebooks.transformers import QuantileThresholdFlag\n",
    "from sklearn import set_config\n",
    "import joblib\n",
    "\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "if \"loc_added\" in df.columns:\n",
    "    # bins = [0, 10, 50, 200, 1000, np.inf]\n",
    "    # labels = [\"very_small\", \"small\", \"medium\", \"large\", \"very_large\"]\n",
    "    # df[\"loc_added_bucket\"] = pd.cut(df[\"loc_added\"], bins=bins, labels=labels)\n",
    "    bins = [0, 2.3, 3.9, 5.3, 7.0, np.inf]\n",
    "    labels = [\"very_small\", \"small\", \"medium\", \"large\", \"very_large\"]\n",
    "\n",
    "    df[\"loc_added_bucket\"] = pd.cut(df[\"loc_added\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# # Example: boolean feature for extreme churn\n",
    "# if \"recent_churn\" in df.columns:\n",
    "#     threshold = df[\"recent_churn\"].quantile(0.95)\n",
    "#     df[\"extreme_churn_flag\"] = (df[\"recent_churn\"] > threshold).astype(int)\n",
    "\n",
    "# df['extreme_churn_flag'].describe()\n",
    "\n",
    "# You'd need to create a list of features for which you want to create a flag\n",
    "# EXTREME_FLAG_FEATURES = [\"recent_churn\"]\n",
    "\n",
    "\n",
    "# if SUBSET == 'train':\n",
    "#     log_check(\"Detected train subset. Creating new preprocessor...\", print_to_console=True)\n",
    "\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         # ... existing transformers ...\n",
    "#         transformers=[('extreme_flags', QuantileThresholdFlag(quantile=0.95), EXTREME_FLAG_FEATURES),\n",
    "#         ]\n",
    "#         # ...\n",
    "#     )\n",
    "\n",
    "#     preprocessor.fit(df)\n",
    "#     df = preprocessor.transform(df)\n",
    "#     joblib.dump(preprocessor, ENGINEERING_PREPROCESSOR)\n",
    "# elif SUBSET in ('test', 'validate'):\n",
    "#     log_check(\"Detected test subset. Loading fitted preprocessor...\", print_to_console=True)\n",
    "#     loaded_preprocessor = joblib.load(ENGINEERING_PREPROCESSOR)\n",
    "#     df = loaded_preprocessor.transform(df)\n",
    "# else:\n",
    "#     msg = \"Unknown subset value!\"\n",
    "#     logger.error(msg)\n",
    "#     raise ValueError(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5cac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2885278464651331\n",
      "0.3129658709954691\n"
     ]
    }
   ],
   "source": [
    "df[\"loc_added_bucket_cat\"] = df[\"loc_added_bucket\"].cat.codes\n",
    "print(df[\"loc_added_bucket_cat\"].corr(df[\"label\"]))\n",
    "print(df['loc_added'].corr(df['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21468a5",
   "metadata": {},
   "source": [
    "#### why loc_add_bucket?\n",
    "\n",
    "Because ML models often perform better when very skewed numeric features are also represented in categorical (binned) form.\n",
    "\n",
    "✓ Models detect thresholds better\n",
    "\n",
    "Bug likelihood typically increases when a commit crosses certain “size” thresholds:\n",
    "\n",
    "- tiny commits (<10 LOC) rarely introduce bugs\n",
    "- medium commits (50–200 LOC) are more risky\n",
    "- huge commits (1000+ LOC) are extremely risky\n",
    "\n",
    "Binning makes these thresholds explicit rather than hidden inside a numeric feature.\n",
    "\n",
    "✓ Models become more robust to noise\n",
    "\n",
    "- Instead of memorizing exact values like “3.044522” (your log-transformed LOC),\n",
    "the model gets a stable category: \"small\".\n",
    "\n",
    "✓ Helps tree-based models (XGBoost, RF, LightGBM)\n",
    "\n",
    "Trees thrive on categorical thresholds.\n",
    "One-hot-encoded buckets give them interpretable splits.\n",
    "\n",
    "\n",
    "#### Why extreme_churn_flag?\n",
    "\n",
    "*recent_churn* = how many lines were changed recently in the project\n",
    "\n",
    "High churn = a project area under rapid change\n",
    "\n",
    "High churn is known in research to correlate with bug-inducing commits\n",
    "(rapidly changing files are less stable)\n",
    "\n",
    "So the idea is:\n",
    "- commits with huge previous churn → more likely to be unstable → possibly bug-inducing\n",
    "\n",
    "This is a domain-inspired feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38478fc",
   "metadata": {},
   "source": [
    "### 6.2.3 - Aggregate LINE_TOKEN_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6ab617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.constants import LINE_TOKEN_FEATURES\n",
    "\n",
    "\n",
    "df[\"line_token_total\"] = df[LINE_TOKEN_FEATURES].sum(axis=1)\n",
    "\n",
    "# Optionally create ratios per total lines (if loc_added exists)\n",
    "if \"loc_added\" in df.columns:\n",
    "    for token in LINE_TOKEN_FEATURES:\n",
    "        df[f\"{token}_ratio\"] = df[token] / (df[\"loc_added\"] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135420d3",
   "metadata": {},
   "source": [
    "### 6.2.4 - Feature interactions (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8600196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction_features = [\"loc_added\", \"loc_deleted\", \"hunks_count\"]\n",
    "\n",
    "from notebooks.constants import INTERACTION_FEATURES\n",
    "\n",
    "\n",
    "for i in range(len(INTERACTION_FEATURES)):\n",
    "    for j in range(i+1, len(INTERACTION_FEATURES)):\n",
    "        f1 = INTERACTION_FEATURES[i]\n",
    "        f2 = INTERACTION_FEATURES[j]\n",
    "        df[f\"{f1}_x_{f2}\"] = df[f1] * df[f2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e7eab",
   "metadata": {},
   "source": [
    "<!-- ### 6.2.5 - Expanding embeddings\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "699430f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expand_embedding(df, col_name, prefix):\n",
    "#     emb = np.vstack(df[col_name].values)\n",
    "#     emb_df = pd.DataFrame(\n",
    "#         emb,\n",
    "#         index=df.index,\n",
    "#         columns=[f\"{prefix}_{i}\" for i in range(emb.shape[1])]\n",
    "#     )\n",
    "#     return emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae09fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_emb_df = expand_embedding(df, \"code_embed\", \"code_emb\")\n",
    "# msg_emb_df  = expand_embedding(df, \"msg_embed\", \"msg_emb\")\n",
    "\n",
    "# df = pd.concat(\n",
    "#     [df.drop(columns=[\"code_embed\", \"msg_embed\"]), code_emb_df, msg_emb_df],\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e741f66",
   "metadata": {},
   "source": [
    "## 6.3 - Summary of engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16e39ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENGINEERING RESULT] Engineered features: ['loc_churn_ratio', 'activity_per_exp', 'loc_added_bucket', 'extreme_churn_flag', 'line_token_total', 'todo_ratio', 'fixme_ratio', 'try_ratio', 'except_ratio', 'raise_ratio', 'loc_added_x_loc_deleted', 'loc_added_x_hunks_count', 'loc_deleted_x_hunks_count']\n"
     ]
    }
   ],
   "source": [
    "from notebooks.constants import ENGINEERED_FEATURES\n",
    "\n",
    "\n",
    "# engineered_cols = [c for c in df.columns if c not in NUMERIC_FEATURES + LINE_TOKEN_FEATURES]\n",
    "# msg = \"Engineered features:\", ENGINEERED_FEATURES\n",
    "\n",
    "log_result(f\"Engineered features: {ENGINEERED_FEATURES}\", print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c671b",
   "metadata": {},
   "source": [
    "## 6.4 Save the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f5293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENGINEERING CHECK] Saving preprocessed dataset...\n",
      "[ENGINEERING RESULT] Preprocessed dataset saved to C:\\Users\\fmojt\\Code\\DPThesis\\DP_Thesis\\data\\processed\\train_engineered.feather\n",
      "['author_exp_pre', 'author_recent_activity_pre', 'loc_added', 'loc_deleted', 'files_changed', 'hunks_count', 'msg_len', 'ast_delta', 'complexity_delta', 'max_func_change', 'time_since_last_change', 'recent_churn', 'todo', 'fixme', 'try', 'except', 'raise', 'code_emb_0', 'code_emb_1', 'code_emb_2', 'code_emb_3', 'code_emb_4', 'code_emb_5', 'code_emb_6', 'code_emb_7', 'code_emb_8', 'code_emb_9', 'code_emb_10', 'code_emb_11', 'code_emb_12', 'code_emb_13', 'code_emb_14', 'code_emb_15', 'code_emb_16', 'code_emb_17', 'code_emb_18', 'code_emb_19', 'code_emb_20', 'code_emb_21', 'code_emb_22', 'code_emb_23', 'code_emb_24', 'code_emb_25', 'code_emb_26', 'code_emb_27', 'code_emb_28', 'code_emb_29', 'code_emb_30', 'code_emb_31', 'code_emb_32', 'code_emb_33', 'code_emb_34', 'code_emb_35', 'code_emb_36', 'code_emb_37', 'code_emb_38', 'code_emb_39', 'code_emb_40', 'code_emb_41', 'code_emb_42', 'code_emb_43', 'code_emb_44', 'code_emb_45', 'code_emb_46', 'code_emb_47', 'code_emb_48', 'code_emb_49', 'code_emb_50', 'code_emb_51', 'code_emb_52', 'code_emb_53', 'code_emb_54', 'code_emb_55', 'code_emb_56', 'code_emb_57', 'code_emb_58', 'code_emb_59', 'code_emb_60', 'code_emb_61', 'code_emb_62', 'code_emb_63', 'code_emb_64', 'code_emb_65', 'code_emb_66', 'code_emb_67', 'code_emb_68', 'code_emb_69', 'code_emb_70', 'code_emb_71', 'code_emb_72', 'code_emb_73', 'code_emb_74', 'code_emb_75', 'code_emb_76', 'code_emb_77', 'code_emb_78', 'code_emb_79', 'code_emb_80', 'code_emb_81', 'code_emb_82', 'code_emb_83', 'code_emb_84', 'code_emb_85', 'code_emb_86', 'code_emb_87', 'code_emb_88', 'code_emb_89', 'code_emb_90', 'code_emb_91', 'code_emb_92', 'code_emb_93', 'code_emb_94', 'code_emb_95', 'code_emb_96', 'code_emb_97', 'code_emb_98', 'code_emb_99', 'msg_emb_0', 'msg_emb_1', 'msg_emb_2', 'msg_emb_3', 'msg_emb_4', 'msg_emb_5', 'msg_emb_6', 'msg_emb_7', 'msg_emb_8', 'msg_emb_9', 'msg_emb_10', 'msg_emb_11', 'msg_emb_12', 'msg_emb_13', 'msg_emb_14', 'msg_emb_15', 'msg_emb_16', 'msg_emb_17', 'msg_emb_18', 'msg_emb_19', 'msg_emb_20', 'msg_emb_21', 'msg_emb_22', 'msg_emb_23', 'msg_emb_24', 'msg_emb_25', 'msg_emb_26', 'msg_emb_27', 'msg_emb_28', 'msg_emb_29', 'msg_emb_30', 'msg_emb_31', 'msg_emb_32', 'msg_emb_33', 'msg_emb_34', 'msg_emb_35', 'msg_emb_36', 'msg_emb_37', 'msg_emb_38', 'msg_emb_39', 'msg_emb_40', 'msg_emb_41', 'msg_emb_42', 'msg_emb_43', 'msg_emb_44', 'msg_emb_45', 'msg_emb_46', 'msg_emb_47', 'msg_emb_48', 'msg_emb_49', 'msg_emb_50', 'msg_emb_51', 'msg_emb_52', 'msg_emb_53', 'msg_emb_54', 'msg_emb_55', 'msg_emb_56', 'msg_emb_57', 'msg_emb_58', 'msg_emb_59', 'msg_emb_60', 'msg_emb_61', 'msg_emb_62', 'msg_emb_63', 'msg_emb_64', 'msg_emb_65', 'msg_emb_66', 'msg_emb_67', 'msg_emb_68', 'msg_emb_69', 'msg_emb_70', 'msg_emb_71', 'msg_emb_72', 'msg_emb_73', 'msg_emb_74', 'msg_emb_75', 'msg_emb_76', 'msg_emb_77', 'msg_emb_78', 'msg_emb_79', 'msg_emb_80', 'msg_emb_81', 'msg_emb_82', 'msg_emb_83', 'msg_emb_84', 'msg_emb_85', 'msg_emb_86', 'msg_emb_87', 'msg_emb_88', 'msg_emb_89', 'msg_emb_90', 'msg_emb_91', 'msg_emb_92', 'msg_emb_93', 'msg_emb_94', 'msg_emb_95', 'msg_emb_96', 'msg_emb_97', 'msg_emb_98', 'msg_emb_99', 'datetime', 'commit', 'repo', 'filepath', 'content', 'methods', 'lines', 'author_email', 'canonical_datetime', 'label', 'has_fix_kw', 'has_bug_kw', 'loc_churn_ratio', 'activity_per_exp', 'loc_added_bucket', 'loc_added_bucket_cat', 'line_token_total', 'todo_ratio', 'fixme_ratio', 'try_ratio', 'except_ratio', 'raise_ratio', 'loc_added_x_loc_deleted', 'loc_added_x_hunks_count', 'loc_deleted_x_hunks_count']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_check(\"Saving preprocessed dataset...\")\n",
    "# OUTPUT_PATH = PROCESSED_DATA_DIR / \"train_engineered.feather\"\n",
    "OUTPUT_PATH = ENGINEERING_MAPPINGS[SUBSET]['output']\n",
    "df.to_feather(OUTPUT_PATH)\n",
    "\n",
    "log_result(f\"Preprocessed dataset saved to {OUTPUT_PATH}\", print_to_console=True)\n",
    "\n",
    "my_list = df.columns.values.tolist()\n",
    "print(my_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP_Thesis-sh7Ft33M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
